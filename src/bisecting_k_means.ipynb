{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Analysis Using Bisecting K-Means Clustering\n",
    "\n",
    "Bisecting k-means clustering, from `scikit-learn` is a derivative of\n",
    "k-means clustering that is typically more efficient, due to its\n",
    "bisecting nature. This process, also changes how clusters and\n",
    "centroids are selected, resulting in a completely different, while\n",
    "still somewhat similar, analysis compared to using k-means.\n",
    "\n",
    "The largest difference between the two is the way clusters are created.\n",
    "With bisecting k-means, by default the model will select the cluster\n",
    "with the biggest inertia to be split. This process of selecting and\n",
    "splitting happens recursively until the desired number of clusters is\n",
    "reached. Whereas k-means iteratively tries to separate samples into\n",
    "groups of equal variance. The recursive nature of bisecting k-means\n",
    "commonly gives the output a hierarchy, which can drastically differ\n",
    "from k-means.\n",
    "\n",
    "The process to perform this cluster analysis is very similar, so\n",
    "let's get started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Dependencies and Importing Libraries\n",
    "\n",
    "Again, we have to install and import some things to perform any analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install matplotlib==\"3.8.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import BisectingKMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing Bisecting K-Means Cluster Analysis on Solar Farm Data\n",
    "\n",
    "### Prepping the Data\n",
    "\n",
    "Like always, we start by loading our data into a `pandas` data frame. We can then examine the data frame to see what we want to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/solar.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we are looking at trying to draw conclusions about locational data and their relation to weather properties,\n",
    "so similarly to k-means, lets go with `lat`, `long`, and `irradiance` this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.loc[:, df.columns[1:4]]\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering the Data\n",
    "\n",
    "Now that the data is prepped and ready to go, we can begin clustering it.\n",
    "Even though it is a different data set, lets go with the \"optimal\" cluster\n",
    "number we got from the last notebook to start. This can always be changed later\n",
    "to examine different outputs.\n",
    "\n",
    "So, here we set `n_clusters` to 20, and just create the model. This may look simpler\n",
    "than the k-means process, but the bisecting k-means function call comes with\n",
    "desirable default parameters. Some of these include:\n",
    "\n",
    "- `init`: This defaults to `\"random\"`, which randomly chooses cluster centroids,\n",
    "    which is very different from how k-means handles this process.\n",
    "- `n_init`: This defaults to `1`, meaning that no other seeds are considered. It makes the\n",
    "    assumption that one round of random choices is suitable.\n",
    "- `algorithm`: This defaults to `lloyd`, which is a classical EM-style bisection algorithm\n",
    "    used to split clusters.\n",
    "\n",
    "Although it cannot be seen, this algorithm offers a wider riange of interesting specifications,\n",
    "it just so happens that the default values are different enough from k-means that there is no\n",
    "need to change them.\n",
    "\n",
    "With that said, let's make and fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 20\n",
    "\n",
    "bkmeans = BisectingKMeans(n_clusters)\n",
    "bkmeans.fit(X[X.columns[0:2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to before, after fitting, we can make predictions using the same `fit_predict` method. The cluster values assigned are then stored\n",
    "in a new column in our isolated data set headed `cluster_label`. This can also be seen in a truncated version of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X['cluster_label'] = bkmeans.fit_predict(X[X.columns[0:2]])\n",
    "print(X.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can grab the centroids for our bisecting k-means model, as well as take those labels\n",
    "from above and store them in a variable `labels` used for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = bkmeans.cluster_centers_\n",
    "labels = bkmeans.predict(X[X.columns[0:2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization of this model is the same and with k-means. We start by plotting our isolated data on the bottom.\n",
    "Each data point is assigned a color based on its `cluster_label`. We then plot the centroids on top, which then\n",
    "creates a complete plot that showcases our clusters with centroids within."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.plot.scatter(x = 'long', y = 'lat', c=labels, s=50, cmap='viridis')\n",
    "plt.scatter(centers[:, 1], centers[:, 0], c='black', s=200, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, we can make out the United States again. But notice the shape and placement\n",
    "of the clusters. Even though it is different data, the hierarchy is clearly visible here,\n",
    "which is so much different from the seemingly random dispersion seen in the k-means\n",
    "clustering. Like before, try experimenting with the number of clusters by changing the value\n",
    "of `n_clusters` above, and re-running the cells. Make note of any differences, as well as how\n",
    "prevalent, or ambigous the hierarchy becomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Clusters\n",
    "\n",
    "Once your experimentation is completed, if it is desired, one can save the output of the most recent cluster labeling.\n",
    "By running the cell below the saved data will be put into the `output` directory with the name `bisecting_k_means_output.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv('../output/bisecting_k_means_output.csv', index=None, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "There are no more notebooks to run, but the work here is far from over. To see where this project is heading, visit the `Future Work` section in the [README](../README.md)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
