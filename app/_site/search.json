[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Assessing the Viability and Accuracy of Low-level Machine Learning Models At Predicting Renewable Array Parameters",
    "section": "",
    "text": "This website serves as the artifact for the Allegheny College CMPSC 610 senior comprehensive project. It documents the computational work done to complete the analysis of the machine learning algorithms."
  },
  {
    "objectID": "8-data-clustering.html",
    "href": "8-data-clustering.html",
    "title": "Data Clustering",
    "section": "",
    "text": "Data Clustering Example\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.cluster import KMeans\n\n\ndf = pd.read_csv('../data/wind_old.csv')\nX = df.loc[:, df.columns[1:3]]\n\n\nY_axis = X[['lat']]\nX_axis = X[['long']]\nK_clusters = range(1,100)\nkmeans = [KMeans(n_clusters=i, n_init='auto') for i in K_clusters]\nscore = [kmeans[i].fit(Y_axis).score(Y_axis) for i in range(len(kmeans))]\n\n\nplt.plot(K_clusters, score)\nplt.xlabel('Number of Clusters')\nplt.ylabel('Score')\nplt.title('Elbow Curve')\nplt.show()\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\n\nn_clusters = 20\nkmeans = KMeans(n_clusters, init='k-means++', n_init='auto')\nkmeans.fit(X[X.columns[0:2]])\n\nKMeans(n_clusters=20)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  KMeans?Documentation for KMeansiFittedKMeans(n_clusters=20) \n\n\n\nX['cluster_label'] = kmeans.fit_predict(X[X.columns[0:2]])\nX.head(5)\n\n\n\n\n\n\n\n\nlat\nlong\ncluster_label\n\n\n\n\n0\n23.510410\n-117.147260\n7\n\n\n1\n24.007446\n-93.946777\n6\n\n\n2\n25.069138\n-97.482483\n6\n\n\n3\n25.069443\n-97.463135\n6\n\n\n4\n25.069763\n-97.443756\n6\n\n\n\n\n\n\n\n\ncenters = kmeans.cluster_centers_\nlabels = kmeans.predict(X[X.columns[0:2]])\nX.plot.scatter(x = 'long', y = 'lat', c=labels, s=50, cmap='viridis')\nplt.scatter(centers[:, 1], centers[:, 0], c='black', s=200, alpha=0.5)\nplt.show()\n\n\n\n\n\n\n\nFigure 2"
  },
  {
    "objectID": "4-ann.html",
    "href": "4-ann.html",
    "title": "Artificial Neural Network Analysis",
    "section": "",
    "text": "import pandas as pd\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.preprocessing import StandardScaler"
  },
  {
    "objectID": "4-ann.html#imports",
    "href": "4-ann.html#imports",
    "title": "Artificial Neural Network Analysis",
    "section": "",
    "text": "import pandas as pd\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.preprocessing import StandardScaler"
  },
  {
    "objectID": "4-ann.html#prep-the-data",
    "href": "4-ann.html#prep-the-data",
    "title": "Artificial Neural Network Analysis",
    "section": "Prep the Data",
    "text": "Prep the Data\nFirst, we read in the datasets.\n\nwind_df = pd.read_csv(\"../data/wind.csv\")\nsolar_df = pd.read_csv(\"../data/solar.csv\")\n\nprint(\"Previews of the datasets:\")\nprint(wind_df.head(10))\nprint(\"_________________________________\")\nprint(solar_df.head(10))\n\nPreviews of the datasets:\n   id        lat        long  wind_speed farm_type  capacity  capacity_factor  \\\n0   0  23.510410 -117.147260        6.07  offshore        16            0.169   \n1   1  24.007446  -93.946777        7.43  offshore        16            0.302   \n2   2  25.069138  -97.482483        8.19  offshore        16            0.375   \n3   3  25.069443  -97.463135        8.19  offshore        16            0.375   \n4   4  25.069763  -97.443756        8.19  offshore        16            0.376   \n5   5  25.070091  -97.424377        8.19  offshore        16            0.375   \n6   6  25.070404  -97.404999        8.19  offshore        16            0.375   \n7   7  25.086678  -97.482849        8.18  offshore        16            0.375   \n8   8  25.087006  -97.463470        8.19  offshore        16            0.376   \n9   9  25.087318  -97.444092        8.19  offshore        16            0.376   \n\n   power_generation  estimated_cost  \n0          23687.04        20800000  \n1          42328.32        20800000  \n2          52560.00        20800000  \n3          52560.00        20800000  \n4          52700.16        20800000  \n5          52560.00        20800000  \n6          52560.00        20800000  \n7          52560.00        20800000  \n8          52700.16        20800000  \n9          52700.16        20800000  \n_________________________________\n   id        lat       long  irradiance          farm_type  capacity  \\\n0   0  25.896492 -97.460358    5.634079    large_community     5.000   \n1   1  26.032654 -97.738098    5.616413      small_utility     5.000   \n2   2  26.059063 -97.208252    5.746738    small_community     0.150   \n3   3  26.078449 -98.073364    5.742196      small_utility     5.000   \n4   4  26.143227 -98.311340    5.817187      small_utility     5.000   \n5   5  26.149040 -98.075409    5.701752    large_community     5.000   \n6   6  26.180355 -97.367737    5.720004     medium_utility   500.000   \n7   7  26.254963 -98.078491    5.730308  small_residential     0.005   \n8   8  26.272160 -98.098694    5.734213      large_utility  2000.000   \n9   9  26.272625 -98.078979    5.755140    small_community     0.150   \n\n   capacity_factor  power_generation  estimated_cost  \n0            0.235      1.028219e+04        13300000  \n1            0.234      1.024995e+04        13300000  \n2            0.239      3.146339e+02          399000  \n3            0.239      1.047951e+04        13300000  \n4            0.242      1.061637e+04        13300000  \n5            0.238      1.040570e+04        13300000  \n6            0.238      1.043901e+06      1330000000  \n7            0.239      1.045781e+01           13300  \n8            0.239      4.185975e+06      5320000000  \n9            0.240      3.150939e+02          399000  \n\n\nNow, we must shuffle the datasets to reduce bias.\n\nwind_df = wind_df.sample(frac=1)\nsolar_df = solar_df.sample(frac=1)\n\nprint(\"Previews of the shuffled datasets:\")\nprint(wind_df.head(10))\nprint(\"_________________________________\")\nprint(solar_df.head(10))\n\nPreviews of the shuffled datasets:\n          id        lat        long  wind_speed farm_type  capacity  \\\n16674  16674  34.956932  -97.285461        7.63   onshore        10   \n31096  31096  36.798687 -103.728027        8.75   onshore        16   \n86303  86303  42.880878 -107.222290        8.94   onshore        16   \n97140  97140  44.293499  -96.403290        8.33   onshore        16   \n18893  18893  34.831398 -105.516205        8.24   onshore        16   \n9247    9247  30.578217  -80.625122        7.21  offshore        16   \n55981  55981  40.764744  -89.805542        6.77   onshore        16   \n73821  73821  41.626110  -83.305084        7.25   onshore        10   \n98080  98080  42.294132  -74.849792        7.20   onshore        12   \n6021    6021  29.833126  -90.057617        5.99   onshore        16   \n\n       capacity_factor  power_generation  estimated_cost  \n16674            0.439          38456.40        13000000  \n31096            0.390          54662.40        20800000  \n86303            0.447          62651.52        20800000  \n97140            0.480          67276.80        20800000  \n18893            0.413          57886.08        20800000  \n9247             0.293          41066.88        20800000  \n55981            0.390          54662.40        20800000  \n73821            0.452          39595.20        13000000  \n98080            0.374          39314.88        15600000  \n6021             0.291          40786.56        20800000  \n_________________________________\n          id        lat        long  irradiance           farm_type  capacity  \\\n4967    4967  34.815369 -105.491394    6.543484     small_community     0.150   \n11264  11264  45.323448  -70.688354    4.259140   large_residential     0.015   \n11130  11130  42.872227 -124.405975    4.531468   large_residential     0.015   \n10174  10174  40.820625  -83.971588    4.672360      medium_utility   500.000   \n2721    2721  33.899540 -105.626068    6.486518  medium_residential     0.010   \n10347  10347  41.618584 -107.260391    5.597078       small_utility     5.000   \n9755    9755  38.294769  -96.647552    5.422895   large_residential     0.015   \n4599    4599  34.780090 -105.284241    6.509412     large_community     5.000   \n5872    5872  35.085827 -104.133545    6.532050     large_community     5.000   \n7218    7218  35.588127  -96.395020    5.429985     small_community     0.150   \n\n       capacity_factor  power_generation  estimated_cost  \n4967             0.273        358.255761          399000  \n11264            0.177         23.318794           39900  \n11130            0.189         24.809787           39900  \n10174            0.195     852705.689600      1330000000  \n2721             0.270         23.675792           26600  \n10347            0.233      10214.667070        13300000  \n9755             0.226         29.690352           39900  \n4599             0.271      11879.677430        13300000  \n5872             0.272      11920.990620        13300000  \n7218             0.226        297.291681          399000  \n\n\nLooking at each dataset, we can identify which variables we want to use for our models.\n\n# Wind data\nwind_X = wind_df.loc[:, [False, True, True, True, False, True, True, False, False]]\nwind_y = wind_df.loc[:, [False, False, False, False, False, False, False, True, True]]\n\n# Solar data\nsolar_X = solar_df.loc[:, [False, True, True, True, False, True, True, False, False]]\nsolar_y = solar_df.loc[:, [False, False, False, False, False, False, False, True, True]]\n\nNow we split into training and testing sets, reserving about 80% for training and 20% for testing.\n\n# Wind data\nwind_X_train = wind_X[:100000]\nwind_X_test = wind_X[100000:]\nwind_y_train = wind_y[:100000]\nwind_y_test = wind_y[100000:]\n\n# Solar data\nsolar_X_train = solar_X[:9500]\nsolar_X_test = solar_X[9500:]\nsolar_y_train = solar_y[:9500]\nsolar_y_test = solar_y[9500:]\n\nSome models perform better when inputs are within a certain range, like [-1, 1] for example. We scale the data points appropriately.\n\nscaler = StandardScaler()\n\n# Wind data\nscaler.fit(wind_X_train)\nwind_X_train = scaler.transform(wind_X_train)\nwind_X_test = scaler.transform(wind_X_test)\n\n# Solar data\nscaler.fit(solar_X_train)\nsolar_X_train = scaler.transform(solar_X_train)\nsolar_X_test = scaler.transform(solar_X_test)"
  },
  {
    "objectID": "4-ann.html#training-the-models",
    "href": "4-ann.html#training-the-models",
    "title": "Artificial Neural Network Analysis",
    "section": "Training the Models",
    "text": "Training the Models\nNow that the data is pre-processed accordingly, the models can be trained and fit. Here we are using one hidden layer with three neurons. This is because we have five inputs and two outputs. A good base sees that the number if hidden layers is one, and the neurons in the layer in the mean of the number of input neurons and output neurons.\n\n# Wind network\nwind_reg = MLPRegressor(solver='lbfgs', hidden_layer_sizes=(3,), random_state=0, max_iter=10000000)\nwind_reg.fit(wind_X_train,wind_y_train)\n\n# Solar network\nsolar_reg = MLPRegressor(solver='lbfgs', hidden_layer_sizes=(3,), random_state=0, max_iter=10000000)\nsolar_reg.fit(solar_X_train,solar_y_train)"
  },
  {
    "objectID": "4-ann.html#testing-the-models",
    "href": "4-ann.html#testing-the-models",
    "title": "Artificial Neural Network Analysis",
    "section": "Testing the Models",
    "text": "Testing the Models\nWith trained models, we can now test them and make predictions.\n\n# Wind\nwind_test = wind_reg.predict(wind_X_test)\nprint(\"Predicted outputs for wind data:\")\nprint(wind_test)\nprint()\n\n# Solar\nsolar_test = solar_reg.predict(solar_X_test)\nprint(\"Predicted outputs for solar data:\")\nprint(solar_test)\n\nPredicted outputs for wind data:\n[[   48471.98659213 20800000.08280838]\n [   27821.83910046 12999999.49475553]\n [   64951.41492174 20799999.9461454 ]\n ...\n [   46267.09931196 20800000.09463431]\n [   37284.20825834 15599999.6789072 ]\n [   60126.02035649 20799999.97129241]]\n\nPredicted outputs for solar data:\n[[2.31356074e+01 2.93817331e+04]\n [1.08407627e+04 1.32998520e+07]\n [3.17267784e+01 3.98875099e+04]\n ...\n [4.33695709e+06 5.32000006e+09]\n [1.08418042e+04 1.33000457e+07]\n [3.20134992e+01 3.99386307e+04]]"
  },
  {
    "objectID": "2-rf.html",
    "href": "2-rf.html",
    "title": "Random Forest Regression Analysis",
    "section": "",
    "text": "import pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler"
  },
  {
    "objectID": "2-rf.html#imports",
    "href": "2-rf.html#imports",
    "title": "Random Forest Regression Analysis",
    "section": "",
    "text": "import pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler"
  },
  {
    "objectID": "2-rf.html#prep-the-data",
    "href": "2-rf.html#prep-the-data",
    "title": "Random Forest Regression Analysis",
    "section": "Prep the Data",
    "text": "Prep the Data\nFirst, we read in the datasets.\n\nwind_df = pd.read_csv(\"../data/wind.csv\")\nsolar_df = pd.read_csv(\"../data/solar.csv\")\n\nprint(\"Previews of the datasets:\")\nprint(wind_df.head(10))\nprint(\"_________________________________\")\nprint(solar_df.head(10))\n\nPreviews of the datasets:\n   id        lat        long  wind_speed farm_type  capacity  capacity_factor  \\\n0   0  23.510410 -117.147260        6.07  offshore        16            0.169   \n1   1  24.007446  -93.946777        7.43  offshore        16            0.302   \n2   2  25.069138  -97.482483        8.19  offshore        16            0.375   \n3   3  25.069443  -97.463135        8.19  offshore        16            0.375   \n4   4  25.069763  -97.443756        8.19  offshore        16            0.376   \n5   5  25.070091  -97.424377        8.19  offshore        16            0.375   \n6   6  25.070404  -97.404999        8.19  offshore        16            0.375   \n7   7  25.086678  -97.482849        8.18  offshore        16            0.375   \n8   8  25.087006  -97.463470        8.19  offshore        16            0.376   \n9   9  25.087318  -97.444092        8.19  offshore        16            0.376   \n\n   power_generation  estimated_cost  \n0          23687.04        20800000  \n1          42328.32        20800000  \n2          52560.00        20800000  \n3          52560.00        20800000  \n4          52700.16        20800000  \n5          52560.00        20800000  \n6          52560.00        20800000  \n7          52560.00        20800000  \n8          52700.16        20800000  \n9          52700.16        20800000  \n_________________________________\n   id        lat       long  irradiance          farm_type  capacity  \\\n0   0  25.896492 -97.460358    5.634079    large_community     5.000   \n1   1  26.032654 -97.738098    5.616413      small_utility     5.000   \n2   2  26.059063 -97.208252    5.746738    small_community     0.150   \n3   3  26.078449 -98.073364    5.742196      small_utility     5.000   \n4   4  26.143227 -98.311340    5.817187      small_utility     5.000   \n5   5  26.149040 -98.075409    5.701752    large_community     5.000   \n6   6  26.180355 -97.367737    5.720004     medium_utility   500.000   \n7   7  26.254963 -98.078491    5.730308  small_residential     0.005   \n8   8  26.272160 -98.098694    5.734213      large_utility  2000.000   \n9   9  26.272625 -98.078979    5.755140    small_community     0.150   \n\n   capacity_factor  power_generation  estimated_cost  \n0            0.235      1.028219e+04        13300000  \n1            0.234      1.024995e+04        13300000  \n2            0.239      3.146339e+02          399000  \n3            0.239      1.047951e+04        13300000  \n4            0.242      1.061637e+04        13300000  \n5            0.238      1.040570e+04        13300000  \n6            0.238      1.043901e+06      1330000000  \n7            0.239      1.045781e+01           13300  \n8            0.239      4.185975e+06      5320000000  \n9            0.240      3.150939e+02          399000  \n\n\nNow, we must shuffle the datasets to reduce bias.\n\nwind_df = wind_df.sample(frac=1)\nsolar_df = solar_df.sample(frac=1)\n\nprint(\"Previews of the shuffled datasets:\")\nprint(wind_df.head(10))\nprint(\"_________________________________\")\nprint(solar_df.head(10))\n\nPreviews of the shuffled datasets:\n            id        lat        long  wind_speed farm_type  capacity  \\\n68627    68627  41.921593  -92.838684        7.59   onshore        16   \n25972    25972  36.406723  -99.578583        8.07   onshore        16   \n117318  117318  44.622005  -70.790405        7.73   onshore        10   \n48875    48875  39.382561  -83.549896        6.85   onshore        16   \n69534    69534  41.455593 -107.204559       10.09   onshore        16   \n81785    81785  43.028027 -100.520996        8.15   onshore        16   \n65898    65898  41.775879  -94.841034        8.03   onshore        16   \n15177    15177  34.647572  -94.876343        8.65   onshore        14   \n41287    41287  36.667110  -75.807404        8.17  offshore        16   \n38991    38991  35.806236 -117.794632        5.85   onshore        16   \n\n        capacity_factor  power_generation  estimated_cost  \n68627             0.420          58867.20        20800000  \n25972             0.445          62371.20        20800000  \n117318            0.418          36616.80        13000000  \n48875             0.388          54382.08        20800000  \n69534             0.489          68538.24        20800000  \n81785             0.453          63492.48        20800000  \n65898             0.458          64193.28        20800000  \n15177             0.479          58744.56        18200000  \n41287             0.384          53821.44        20800000  \n38991             0.276          38684.16        20800000  \n_________________________________\n          id        lat        long  irradiance           farm_type  capacity  \\\n9338    9338  36.022804  -93.761475    5.272909     large_community     5.000   \n10150  10150  40.978394  -86.422150    4.709095     small_community     0.150   \n9327    9327  36.035870  -94.443054    5.324147       small_utility     5.000   \n5074    5074  33.166306 -116.199585    6.884232     large_community     5.000   \n10719  10719  43.046040  -82.736023    4.443865    medium_community     2.000   \n6317    6317  35.270199 -102.397247    6.360666   large_residential     0.015   \n3551    3551  34.542427 -101.368805    6.228834     large_community     5.000   \n3554    3554  34.546082 -101.302307    6.235395      medium_utility   500.000   \n9560    9560  34.443386 -117.679779    6.854829  medium_residential     0.010   \n4730    4730  34.796165 -105.308975    6.498895  medium_residential     0.010   \n\n       capacity_factor  power_generation  estimated_cost  \n9338             0.220      9.623058e+03        13300000  \n10150            0.196      2.578229e+02          399000  \n9327             0.222      9.716568e+03        13300000  \n5074             0.287      1.256372e+04        13300000  \n10719            0.185      3.244022e+03         5320000  \n6317             0.265      3.482465e+01           39900  \n3551             0.260      1.136762e+04        13300000  \n3554             0.260      1.137960e+06      1330000000  \n9560             0.286      2.502013e+01           26600  \n4730             0.271      2.372097e+01           26600  \n\n\nLooking at each dataset, we can identify which variables we want to use for our models.\n\n# Wind data\nwind_X = wind_df.loc[:, [False, True, True, True, False, True, True, False, False]]\nwind_y = wind_df.loc[:, [False, False, False, False, False, False, False, True, True]]\n\n# Solar data\nsolar_X = solar_df.loc[:, [False, True, True, True, False, True, True, False, False]]\nsolar_y = solar_df.loc[:, [False, False, False, False, False, False, False, True, True]]\n\nNow we split into training and testing sets, reserving about 80% for training and 20% for testing.\n\n# Wind data\nwind_X_train = wind_X[:100000]\nwind_X_test = wind_X[100000:]\nwind_y_train = wind_y[:100000]\nwind_y_test = wind_y[100000:]\n\n# Solar data\nsolar_X_train = solar_X[:9500]\nsolar_X_test = solar_X[9500:]\nsolar_y_train = solar_y[:9500]\nsolar_y_test = solar_y[9500:]\n\nSome models perform better when inputs are within a certain range, like [-1, 1] for example. We scale the data points appropriately.\n\nscaler = StandardScaler()\n\n# Wind data\nscaler.fit(wind_X_train)\nwind_X_train = scaler.transform(wind_X_train)\nwind_X_test = scaler.transform(wind_X_test)\n\n# Solar data\nscaler.fit(solar_X_train)\nsolar_X_train = scaler.transform(solar_X_train)\nsolar_X_test = scaler.transform(solar_X_test)"
  },
  {
    "objectID": "2-rf.html#training-the-models",
    "href": "2-rf.html#training-the-models",
    "title": "Random Forest Regression Analysis",
    "section": "Training the Models",
    "text": "Training the Models\nNow that the data is pre-processed accordingly, the models can be trained and fit. Here, we set random state to zero to ensure consistency between both data sets, and re-runs of the training and fitting.\n\n# Wind regression\nwind_reg = RandomForestRegressor(random_state=0)\nwind_reg.fit(wind_X_train, wind_y_train)\n\n# Solar regression\nsolar_reg = RandomForestRegressor(random_state=0)\nsolar_reg.fit(solar_X_train, solar_y_train)"
  },
  {
    "objectID": "2-rf.html#testing-the-models",
    "href": "2-rf.html#testing-the-models",
    "title": "Random Forest Regression Analysis",
    "section": "Testing the Models",
    "text": "Testing the Models\nWith trained models, we can now test them and make predictions.\n\n# Wind\nwind_test = wind_reg.predict(wind_X_test)\nprint(\"Predicted outputs for wind data:\")\nprint(wind_test)\nprint()\n\n# Solar\nsolar_test = solar_reg.predict(solar_X_test)\nprint(\"Predicted outputs for solar data:\")\nprint(solar_test)\n\nPredicted outputs for wind data:\n[[   36161.28   20800000.    ]\n [   58586.88   20800000.    ]\n [   76248.4416 20800000.    ]\n ...\n [   38684.16   15600000.    ]\n [   66996.48   20800000.    ]\n [   60829.44   20800000.    ]]\n\nPredicted outputs for solar data:\n[[1.01526034e+01 1.33000000e+04]\n [9.62149950e+03 1.33000000e+07]\n [1.18088103e+01 1.33000000e+04]\n ...\n [2.29657039e+01 2.66000000e+04]\n [1.16820008e+04 1.33000000e+07]\n [2.68208152e+02 3.99000000e+05]]"
  },
  {
    "objectID": "1-datasets.html",
    "href": "1-datasets.html",
    "title": "Data Preview",
    "section": "",
    "text": "import pandas as pd\n\n\nwind_old_df = pd.read_csv('../data/wind_old.csv')\nsolar_old_df = pd.read_csv('../data/solar_old.csv')\nwind_df = pd.read_csv('../data/wind.csv')\nsolar_df = pd.read_csv('../data/solar.csv')\n\n\nwind_old_df.head(5)\n\n\n\n\n\n\n\n\nid\nlat\nlong\nwind_speed\nfarm_type\ncapacity\ncapacity_factor\npower_generation\nestimated_cost\n\n\n\n\n0\n0\n23.510410\n-117.147260\n6.07\noffshore\n16\n0.169\n23687.04\n20800000\n\n\n1\n1\n24.007446\n-93.946777\n7.43\noffshore\n16\n0.302\n42328.32\n20800000\n\n\n2\n2\n25.069138\n-97.482483\n8.19\noffshore\n16\n0.375\n52560.00\n20800000\n\n\n3\n3\n25.069443\n-97.463135\n8.19\noffshore\n16\n0.375\n52560.00\n20800000\n\n\n4\n4\n25.069763\n-97.443756\n8.19\noffshore\n16\n0.376\n52700.16\n20800000\n\n\n\n\n\n\n\n\nsolar_old_df.head(5)\n\n\n\n\n\n\n\n\nid\nlat\nlong\nirradiance\nfarm_type\ncapacity\ncapacity_factor\npower_generation\nestimated_cost\n\n\n\n\n0\n0\n25.896492\n-97.460358\n5.634079\nlarge_community\n5.00\n0.235\n10282.193270\n13300000\n\n\n1\n1\n26.032654\n-97.738098\n5.616413\nsmall_utility\n5.00\n0.234\n10249.953070\n13300000\n\n\n2\n2\n26.059063\n-97.208252\n5.746738\nsmall_community\n0.15\n0.239\n314.633929\n399000\n\n\n3\n3\n26.078449\n-98.073364\n5.742196\nsmall_utility\n5.00\n0.239\n10479.506980\n13300000\n\n\n4\n4\n26.143227\n-98.311340\n5.817187\nsmall_utility\n5.00\n0.242\n10616.365970\n13300000\n\n\n\n\n\n\n\n\nwind_df.head(5)\n\n\n\n\n\n\n\n\nid\nlat\nlong\nstate\nfarm_type\nwind_speed\nlcoe\ncapacity\ncapacity_factor\navailable_wind_power\navailable_energy\ngenerated_energy\ncost\n\n\n\n\n0\n0\n25.896492\n-97.460358\nTexas\nonshore\n7.46\n31\n2\n0.433\n1.997163\n17495.14630\n7575.398348\n4.696747e+06\n\n\n1\n1\n26.032654\n-97.738098\nTexas\nonshore\n7.45\n31\n10\n0.414\n9.945710\n87124.42376\n36069.511440\n2.236310e+07\n\n\n2\n2\n26.059063\n-97.208252\nTexas\nonshore\n8.18\n31\n2\n0.506\n2.633037\n23065.40088\n11671.092850\n7.236078e+06\n\n\n3\n3\n26.078449\n-98.073364\nTexas\nonshore\n7.17\n31\n16\n0.363\n14.185493\n124264.92160\n45108.166540\n2.796706e+07\n\n\n4\n4\n26.143227\n-98.311340\nTexas\nonshore\n7.06\n31\n16\n0.358\n13.542570\n118632.91080\n42470.582050\n2.633176e+07\n\n\n\n\n\n\n\n\nsolar_df.head(5)\n\n\n\n\n\n\n\n\nid\nlat\nlong\nstate\nfarm_type\nirradiance\nlcoe\ncapacity\ncapacity_factor\narray_area\navailable_solar_resource\ngenerated_energy\ncost\n\n\n\n\n0\n0\n25.896492\n-97.460358\nTexas\nlarge_community\n5.634079\n39\n5.00\n0.235\n90633.862770\n21.276596\n6132.00\n4782960.0\n\n\n1\n1\n26.032654\n-97.738098\nTexas\nsmall_utility\n5.616413\n39\n5.00\n0.234\n91307.484990\n21.367521\n6132.00\n4782960.0\n\n\n2\n2\n26.059063\n-97.208252\nTexas\nsmall_community\n5.746738\n39\n0.15\n0.239\n2621.097459\n0.627615\n183.96\n143488.8\n\n\n3\n3\n26.078449\n-98.073364\nTexas\nsmall_utility\n5.742196\n39\n5.00\n0.239\n87439.036330\n20.920502\n6132.00\n4782960.0\n\n\n4\n4\n26.143227\n-98.311340\nTexas\nsmall_utility\n5.817187\n39\n5.00\n0.242\n85241.850210\n20.661157\n6132.00\n4782960.0"
  },
  {
    "objectID": "3-svm.html",
    "href": "3-svm.html",
    "title": "Support Vector Machines Analysis",
    "section": "",
    "text": "import pandas as pd\nfrom sklearn import svm\nfrom sklearn.preprocessing import StandardScaler"
  },
  {
    "objectID": "3-svm.html#imports",
    "href": "3-svm.html#imports",
    "title": "Support Vector Machines Analysis",
    "section": "",
    "text": "import pandas as pd\nfrom sklearn import svm\nfrom sklearn.preprocessing import StandardScaler"
  },
  {
    "objectID": "3-svm.html#prep-the-data",
    "href": "3-svm.html#prep-the-data",
    "title": "Support Vector Machines Analysis",
    "section": "Prep the Data",
    "text": "Prep the Data\nFirst, we read in the datasets.\n\nwind_df = pd.read_csv(\"../data/wind.csv\")\nsolar_df = pd.read_csv(\"../data/solar.csv\")\n\nprint(\"Previews of the datasets:\")\nprint(wind_df.head(10))\nprint(\"_________________________________\")\nprint(solar_df.head(10))\n\nPreviews of the datasets:\n   id        lat        long  wind_speed farm_type  capacity  capacity_factor  \\\n0   0  23.510410 -117.147260        6.07  offshore        16            0.169   \n1   1  24.007446  -93.946777        7.43  offshore        16            0.302   \n2   2  25.069138  -97.482483        8.19  offshore        16            0.375   \n3   3  25.069443  -97.463135        8.19  offshore        16            0.375   \n4   4  25.069763  -97.443756        8.19  offshore        16            0.376   \n5   5  25.070091  -97.424377        8.19  offshore        16            0.375   \n6   6  25.070404  -97.404999        8.19  offshore        16            0.375   \n7   7  25.086678  -97.482849        8.18  offshore        16            0.375   \n8   8  25.087006  -97.463470        8.19  offshore        16            0.376   \n9   9  25.087318  -97.444092        8.19  offshore        16            0.376   \n\n   power_generation  estimated_cost  \n0          23687.04        20800000  \n1          42328.32        20800000  \n2          52560.00        20800000  \n3          52560.00        20800000  \n4          52700.16        20800000  \n5          52560.00        20800000  \n6          52560.00        20800000  \n7          52560.00        20800000  \n8          52700.16        20800000  \n9          52700.16        20800000  \n_________________________________\n   id        lat       long  irradiance          farm_type  capacity  \\\n0   0  25.896492 -97.460358    5.634079    large_community     5.000   \n1   1  26.032654 -97.738098    5.616413      small_utility     5.000   \n2   2  26.059063 -97.208252    5.746738    small_community     0.150   \n3   3  26.078449 -98.073364    5.742196      small_utility     5.000   \n4   4  26.143227 -98.311340    5.817187      small_utility     5.000   \n5   5  26.149040 -98.075409    5.701752    large_community     5.000   \n6   6  26.180355 -97.367737    5.720004     medium_utility   500.000   \n7   7  26.254963 -98.078491    5.730308  small_residential     0.005   \n8   8  26.272160 -98.098694    5.734213      large_utility  2000.000   \n9   9  26.272625 -98.078979    5.755140    small_community     0.150   \n\n   capacity_factor  power_generation  estimated_cost  \n0            0.235      1.028219e+04        13300000  \n1            0.234      1.024995e+04        13300000  \n2            0.239      3.146339e+02          399000  \n3            0.239      1.047951e+04        13300000  \n4            0.242      1.061637e+04        13300000  \n5            0.238      1.040570e+04        13300000  \n6            0.238      1.043901e+06      1330000000  \n7            0.239      1.045781e+01           13300  \n8            0.239      4.185975e+06      5320000000  \n9            0.240      3.150939e+02          399000  \n\n\nNow, we must shuffle the datasets to reduce bias.\n\nwind_df = wind_df.sample(frac=1)\nsolar_df = solar_df.sample(frac=1)\n\nprint(\"Previews of the shuffled datasets:\")\nprint(wind_df.head(10))\nprint(\"_________________________________\")\nprint(solar_df.head(10))\n\nPreviews of the shuffled datasets:\n            id        lat        long  wind_speed farm_type  capacity  \\\n2538      2538  28.427433  -95.482086        7.43  offshore        16   \n74685    74685  42.460751  -97.424561        8.70   onshore        16   \n14832    14832  34.077995 -105.496582        8.78   onshore        16   \n62697    62697  41.330143  -89.920837        7.48   onshore        16   \n126102  126102  48.964993 -112.273132        8.37   onshore        16   \n47952    47952  38.612041 -112.771744        6.21   onshore        10   \n70149    70149  42.003757  -91.957764        7.48   onshore        14   \n37703    37703  36.501045 -113.198120        6.94   onshore        16   \n1669      1669  26.541775  -82.296326        5.95  offshore        16   \n97832    97832  42.256721  -74.759338        7.23   onshore        10   \n\n        capacity_factor  power_generation  estimated_cost  \n2538              0.311          43589.76        20800000  \n74685             0.508          71201.28        20800000  \n14832             0.445          62371.20        20800000  \n62697             0.409          57325.44        20800000  \n126102            0.385          53961.60        20800000  \n47952             0.311          27243.60        13000000  \n70149             0.415          50895.60        18200000  \n37703             0.298          41767.68        20800000  \n1669              0.195          27331.20        20800000  \n97832             0.424          37142.40        13000000  \n_________________________________\n        id        lat        long  irradiance           farm_type  capacity  \\\n2729  2729  33.916904 -105.451294    6.432974     large_community     5.000   \n199    199  27.048847  -98.839020    5.774646   large_residential     0.015   \n2495  2495  33.808910 -105.612885    6.476483       large_utility  2000.000   \n7049  7049  35.423641 -101.373810    6.163073    medium_community     2.000   \n3134  3134  34.097244 -105.299377    6.415791   small_residential     0.005   \n7259  7259  35.172871 -105.227356    6.439467  medium_residential     0.010   \n5593  5593  35.001354 -104.685379    6.581329   large_residential     0.015   \n7649  7649  35.608040  -99.783325    5.953158     large_community     5.000   \n5346  5346  35.027256 -103.721466    6.482349  medium_residential     0.010   \n1294  1294  30.845142 -103.887756    6.407234       large_utility  2000.000   \n\n      capacity_factor  power_generation  estimated_cost  \n2729            0.268      1.174018e+04        13300000  \n199             0.241      3.161619e+01           39900  \n2495            0.270      4.727832e+06      5320000000  \n7049            0.257      4.499043e+03         5320000  \n3134            0.267      1.170882e+01           13300  \n7259            0.268      2.350405e+01           26600  \n5593            0.274      3.603278e+01           39900  \n7649            0.248      1.086451e+04        13300000  \n5346            0.270      2.366058e+01           26600  \n1294            0.267      4.677281e+06      5320000000  \n\n\nLooking at each dataset, we can identify which variables we want to use for our models. SVM can only handle 1D predictions, so we have to separate the two desired outputs into their own sets.\n\n# Wind data: energy production\nwind_X = wind_df.loc[:, [False, True, True, True, False, True, True, False, False]]\nwind_energy_y = wind_df.loc[:, wind_df.columns[-2]]\n\n# Wind data: cost\nwind_cost_y = wind_df.loc[:, wind_df.columns[-1]]\n\n# Solar data: energy production\nsolar_X = solar_df.loc[:, [False, True, True, True, False, True, True, False, False]]\nsolar_energy_y = solar_df.loc[:, solar_df.columns[-2]]\n\n# Solar data: cost\nsolar_cost_y = solar_df.loc[:, solar_df.columns[-1]]\n\nNow we split into training and testing sets, making sure each output get its own training and testing set, reserving about 80% for training and 20% for testing.\n\n# Wind data: energy production\nwind_X_train = wind_X[:100000]\nwind_X_test = wind_X[100000:]\nwind_energy_y_train = wind_energy_y[:100000]\nwind_energy_y_test = wind_energy_y[100000:]\n\n# Wind data: cost\nwind_cost_y_train = wind_cost_y[:100000]\nwind_cost_y_test = wind_cost_y[100000:]\n\n# Solar data: energy production\nsolar_X_train = solar_X[:9500]\nsolar_X_test = solar_X[9500:]\nsolar_energy_y_train = solar_energy_y[:9500]\nsolar_energy_y_test = solar_energy_y[9500:]\n\n# Solar data: cost\nsolar_cost_y_train = solar_cost_y[:9500]\nsolar_cost_y_test = solar_cost_y[9500:]\n\nSome models perform better when inputs are within a certain range, like [-1, 1] for example. We scale the data points appropriately.\n\nscaler = StandardScaler()\n\n# Wind data\nscaler.fit(wind_X_train)\nwind_X_train = scaler.transform(wind_X_train)\nwind_X_test = scaler.transform(wind_X_test)\n\n# Solar data\nscaler.fit(solar_X_train)\nsolar_X_train = scaler.transform(solar_X_train)\nsolar_X_test = scaler.transform(solar_X_test)"
  },
  {
    "objectID": "3-svm.html#training-the-models",
    "href": "3-svm.html#training-the-models",
    "title": "Support Vector Machines Analysis",
    "section": "Training the Models",
    "text": "Training the Models\nNow that the data is pre-processed accordingly, the models can be trained and fit.\n\n# Wind: energy production\nwind_energy_reg = svm.SVR()\nwind_energy_reg.fit(wind_X_train, wind_energy_y_train)\n\n\n# Wind: cost\nwind_cost_reg = svm.SVR()\nwind_cost_reg.fit(wind_X_train, wind_cost_y_train)\n\n\n# Solar: energy production\nsolar_energy_reg = svm.SVR()\nsolar_energy_reg.fit(solar_X_train, solar_energy_y_train)\n\n\n#Solar: cost\nsolar_cost_reg = svm.SVR()\nsolar_cost_reg.fit(solar_X_train, solar_cost_y_train)"
  },
  {
    "objectID": "3-svm.html#testing-the-models",
    "href": "3-svm.html#testing-the-models",
    "title": "Support Vector Machines Analysis",
    "section": "Testing the Models",
    "text": "Testing the Models\nWith trained models, we can now test them and make predictions.\n\n# Wind: energy production\nwind_energy_test = wind_energy_reg.predict(wind_X_test)\nprint(\"Predicted outputs for wind energy data:\")\nprint(wind_energy_test)\nprint()\n\n# Wind: cost\nwind_cost_test = wind_cost_reg.predict(wind_X_test)\nprint(\"Predicted outputs for wind cost data:\")\nprint(wind_cost_test)\nprint()\n\n# Solar: energy production\nsolar_energy_test = solar_energy_reg.predict(wind_X_test)\nprint(\"Predicted outputs for solar energy data:\")\nprint(solar_energy_test)\nprint()\n\n# Solar: cost\nsolar_cost_test = solar_cost_reg.predict(wind_X_test)\nprint(\"Predicted outputs for solar cost data:\")\nprint(solar_cost_test)\n\nPredicted outputs for wind energy data:\n[43740.47802981 48651.84476318 55644.30161531 ... 57777.52430673\n 42938.48674883 61054.39411137]\n\nPredicted outputs for wind cost data:\n[20795471.847709   20797202.07397964 20799992.74356124 ...\n 20799999.44791149 20799860.74038213 20799991.1027435 ]\n\nPredicted outputs for solar energy data:\n[4364.28499731 4821.89196899 4700.30967839 ... 4806.56397471 4758.2968372\n 4974.2796332 ]\n\nPredicted outputs for solar cost data:\n[5319985.2501513  5320251.04082778 5320328.99546367 ... 5320366.13373715\n 5320292.87901872 5320344.07807934]"
  },
  {
    "objectID": "5-rf-old.html",
    "href": "5-rf-old.html",
    "title": "Old Random Forest Model",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.legend_handler import HandlerLine2D\nimport sklearn.metrics as metrics\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\ndf = pd.read_csv(\"../data/wind_old.csv\")\ndf = df.sample(frac=1)\n\nX = df.loc[:, [False, True, True, True, False, True, True, False, False]]\ny = df.loc[:, [False, False, False, False, False,False, False, True, True]]\n\nX_train = X[:100000]\nX_test = X[100000:]\ny_train = y[:100000]\ny_test = y[100000:]\n\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\nreg = RandomForestRegressor(random_state=0)\nreg.fit(X_train, y_train)\npreds = reg.predict(X_test)\n\n\n\n\n\n\nfeatures = ['lat','long','wind_speed','capacity','capacity_factor']\nimportances = reg.feature_importances_\nindices = np.argsort(importances)\n\nprint(\"Feature Importances\")\nprint('----------------------------')\nfor i in indices:\n    print(f\"{features[i]}: {importances[i]*100}\")\n\nFeature Importances\n----------------------------\nlat: 1.7415146179729832e-09\nlong: 4.556724073707158e-09\nwind_speed: 2.5874951940190983e-08\ncapacity_factor: 0.0005676720796435423\ncapacity: 99.99943229574717\n\n\n\nplt.title(\"Feature Importances\")\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel(\"Relative Importance\")\nplt.show()\n\n\n\n\n\n\n\nFigure 1"
  },
  {
    "objectID": "5-rf-old.html#graphs",
    "href": "5-rf-old.html#graphs",
    "title": "Old Random Forest Model",
    "section": "",
    "text": "features = ['lat','long','wind_speed','capacity','capacity_factor']\nimportances = reg.feature_importances_\nindices = np.argsort(importances)\n\nprint(\"Feature Importances\")\nprint('----------------------------')\nfor i in indices:\n    print(f\"{features[i]}: {importances[i]*100}\")\n\nFeature Importances\n----------------------------\nlat: 1.7415146179729832e-09\nlong: 4.556724073707158e-09\nwind_speed: 2.5874951940190983e-08\ncapacity_factor: 0.0005676720796435423\ncapacity: 99.99943229574717\n\n\n\nplt.title(\"Feature Importances\")\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel(\"Relative Importance\")\nplt.show()\n\n\n\n\n\n\n\nFigure 1"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "A Look at the Data",
    "section": "",
    "text": "Data are a crucial piece of this research project. As such, much of the effort and consideration went into selecting, crafting, and refactoring the datasets to suit the need as best as possible. Throughout this process, many things were tried and tossed away. These include the form of the data, and even methods for processing the data to make it easier for certain machine learning models to use them. In the end, an effective appraoch was discovered. Each of these snapshots will be covered below.\n\n\nBoth the wind and solar data used in this project orginally come from The National Renewable Energy Laboratory (NREL). The data comes with many attributes that are crucial to the analysis this project seeks to conduct, however, there are still pieces missing to truly acheive the full picture. Regardless, compared to other publically available datasets, these were the best suited for the job, and offered a good starting point.\n\n\nThe original datasets came with some basic attributes:\n\nlongitude\nlatitude\nwind speed\nsolar irradiance\ncapacity\ncapacity factor\n\nThis, at first, is not enough data to begin predicting for energy generation and cost. For this, actual data on energy generation and cost is needed. With what was provided, these could be calculated. To start, a few simple calculations were used to find the energy and cost values desired. The attribute capacity denotes how much energy a certain technology can produce under ideal conditions. Capacity factor denotes what fraction of the technology’s capacity is produced. With this, a simple estimate for energy generation can be calculated by multiplying both values together. For cost, many estimates exist that outline how much a technology costs per watt of installed capacity. Using these estimates, and multiplying by capacity, a value for cost can be aquired. This produced two datasets that took this shape:\n\n\n\n\n\n\n\n\n\n\n\n\nid\nlat\nlong\nwind_speed\nfarm_type\ncapacity\ncapacity_factor\npower_generation\nestimated_cost\n\n\n\n\n0\n0\n23.510410\n-117.147260\n6.07\noffshore\n16\n0.169\n23687.04\n20800000\n\n\n1\n1\n24.007446\n-93.946777\n7.43\noffshore\n16\n0.302\n42328.32\n20800000\n\n\n2\n2\n25.069138\n-97.482483\n8.19\noffshore\n16\n0.375\n52560.00\n20800000\n\n\n3\n3\n25.069443\n-97.463135\n8.19\noffshore\n16\n0.375\n52560.00\n20800000\n\n\n4\n4\n25.069763\n-97.443756\n8.19\noffshore\n16\n0.376\n52700.16\n20800000\n\n\n\n\n\n\n\nSource: Data Preview\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nlat\nlong\nirradiance\nfarm_type\ncapacity\ncapacity_factor\npower_generation\nestimated_cost\n\n\n\n\n0\n0\n25.896492\n-97.460358\n5.634079\nlarge_community\n5.00\n0.235\n10282.193270\n13300000\n\n\n1\n1\n26.032654\n-97.738098\n5.616413\nsmall_utility\n5.00\n0.234\n10249.953070\n13300000\n\n\n2\n2\n26.059063\n-97.208252\n5.746738\nsmall_community\n0.15\n0.239\n314.633929\n399000\n\n\n3\n3\n26.078449\n-98.073364\n5.742196\nsmall_utility\n5.00\n0.239\n10479.506980\n13300000\n\n\n4\n4\n26.143227\n-98.311340\n5.817187\nsmall_utility\n5.00\n0.242\n10616.365970\n13300000\n\n\n\n\n\n\n\nSource: Data Preview\nThe rough and simplistic nature of these estimates are generally okay as the concern of this project is to determine how well machine learning algorithms predict values, and not the correctness and integrity of the values themselves. Nonetheless, issues still appeared because of this. When training and testing the Random Forest Regressor, a feature importance graph was used to determine which attributes are the most important. This can also give insights into how the variables are used by other models as well. When running on the old wind data, the graph indicated one variable was dominating the dataset.\n\n\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\nSource: Old Random Forest Model\n\n\n\nFeature Importances\n----------------------------\nlat: 1.7415146179729832e-09\nlong: 4.556724073707158e-09\nwind_speed: 2.5874951940190983e-08\ncapacity_factor: 0.0005676720796435423\ncapacity: 99.99943229574717\n\n\nSource: Old Random Forest Model\nOut of all of the features, capacity was shown to have the highest importance. This makes sense as both calculations are made up of direct proportions that scale based on capacity. This then indicates that the issue is not Random Forest exclusive, as this bias is present in the dataset, and not in how the algorithm interprets the dataset. Changes had to be implemeneted to remove this bias, which included adding more features and using more in-depth calculations to derive the features to be predicted. These are covered in The New Data.\n\n\n\n\nThe initial direction of this project was to look specifically into clustering techniques and cluster analysis. This process consists of grouping similar data into a specified number of clusters. When considering the geospatial data used for this project, clustering would be used to abstract coordinates in the form of longitude and latitude into a single value, a cluster ID. The cluster ID’s would then represent the other features of the data point, allowing for predictions of other features to be made based off of a given cluster ID or coordinate location. The main two steps for performing the clustering is breifly outlined below:\n\nDetermine the number of optimal clusters for the dataset.\n\nTo do this, you just need to cluster the data with varying cluster numbers, score them, and graph the scores by the number of clusters and determine the point at which gains start to diminish.\n\n\n\n\n\n\n\n\n\nFigure 2\n\n\n\n\n\nSource: Data Clustering\n\nCluster the data and plot the results\n\nWith the optimal number of clusters (or any desired number), the data can be clustered, with each data point given a cluster ID.\n\n\n\n\n\n\n\n\n\n\nlat\nlong\ncluster_label\n\n\n\n\n0\n23.510410\n-117.147260\n7\n\n\n1\n24.007446\n-93.946777\n6\n\n\n2\n25.069138\n-97.482483\n6\n\n\n3\n25.069443\n-97.463135\n6\n\n\n4\n25.069763\n-97.443756\n6\n\n\n\n\n\n\n\nSource: Data Clustering\nNow that clusters are generated, they can be plotted and visualized.\n\n\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\nSource: Data Clustering\nThis not only shows the shape and dimensions of the data, but it also gives insights into how many clusters are suitable for the task. The scale of the data makes the number of optimal clusters here a bit ambiguous. Although around 20 seems to be the best, 20 clusters does not seem to represent the nuances of how geospatial data like wind speed and solar raditation changes throughout the country. This seems to indicate that this approach is a bit unreliable in that regard and could introduce more bias into the data and models.\nAdditionally, the clustering could also help increase the performance of the algorithms by lowering the number of input parameters. Simplifying the inputs allows the models to interpret the data easier, leading to better predictions. The issues described in the structure and make-up section further examplified this potential benefit. But for those same reasons, clustering ended up not being an ideal pathway forward. Not only would refactoring the data to remove the bias negate the benefits of clustering in the long run, but clustering also ends up become computationally expensive and tedious to implement and analyze given the nature of the data. For these reasons it was discarded as an aspect of the project.\n\n\n\n\nTo overcome the issues outlined above, the datasets were both refactored heavily to remove the bias present. This fixed structural issues, but also allowed for in-depth analysis of mahcine learning models without the time and efficiency overheads that would be present if clustering remained a crucial piece of the project. The process and results of refactoring both of the datasets are outlined below:\n\n\nTo reduce the bias in the wind dataset, new features were added and a new equation was used that incorporated more features than just capacity to ensure a wider range of importance across the board. Two new features were added:\n\nState - the state that the latitude and longitude coordinates are within.\nLevelized Cost of Energy (LCOE) - the average net cost of electricity generation for a generator over its lifetime.\n\nBoth of these features gave way for more inclusive calculations to be used for both energy generation and cost. The updated method to find the energy generation, \\(J\\), for a given wind farm uses the following equation where \\(c\\) is capacity, \\(\\rho\\) is the density of air, \\(A\\) is the swept area of the wind turbine, \\(v\\) is the wind speed, \\(h\\) is the number of hours in a year, and \\(c_f\\) is capacity factor:\n\n\\(J = \\frac{c}{2}\\left( \\frac{1}{2}\\rho Av^3\\right)h c_f\\)\nSome values here are assumed constants: \\(\\rho = 1.225 kg/m^3\\), \\(A = 7854 m^2\\), \\(h = 8760hrs\\)\n\nAlso, this equation was split at certain parts to increase the number of features, to aide the model in being able to track the relationships better. The splits added the features available_wind_power and available_energy.\nCalculating the cost using LCOE is very simple. A technology’s LCOE is measured in dollars per watt-hour of energy generated. The only other piece needed is the lifespan of the technology. For this project, a 20 year lifespan is assumed for all wind turbines. This results in this equation where \\(J\\) is generated energy, \\(l\\) is the LCOE of the technology in the state, and \\(t\\) is the lifespan of the technology:\n\n\\(C = Jlt\\)\n\nThese equations incorporate crucial pieces of geospatial data that were not present in the previous calculation. It also adds other assumed constants, which add complexity to the calculation and obscure the relationships a bit, giving the model more agency to work out the connections. In the end, it results in a dataset that looks like this:\n\n\n\n\n\n\n\n\n\n\nid\nlat\nlong\nstate\nfarm_type\nwind_speed\nlcoe\ncapacity\ncapacity_factor\navailable_wind_power\navailable_energy\ngenerated_energy\ncost\n\n\n\n\n0\n0\n25.896492\n-97.460358\nTexas\nonshore\n7.46\n31\n2\n0.433\n1.997163\n17495.14630\n7575.398348\n4.696747e+06\n\n\n1\n1\n26.032654\n-97.738098\nTexas\nonshore\n7.45\n31\n10\n0.414\n9.945710\n87124.42376\n36069.511440\n2.236310e+07\n\n\n2\n2\n26.059063\n-97.208252\nTexas\nonshore\n8.18\n31\n2\n0.506\n2.633037\n23065.40088\n11671.092850\n7.236078e+06\n\n\n3\n3\n26.078449\n-98.073364\nTexas\nonshore\n7.17\n31\n16\n0.363\n14.185493\n124264.92160\n45108.166540\n2.796706e+07\n\n\n4\n4\n26.143227\n-98.311340\nTexas\nonshore\n7.06\n31\n16\n0.358\n13.542570\n118632.91080\n42470.582050\n2.633176e+07\n\n\n\n\n\n\n\nSource: Data Preview\nThis dataset can be accessed and downloaded from here.\n\n\n\nSimilar to the wind dataset, bias was reduced by adding more features and using a new equation which incorporated more features. Like the wind data, to make these adjustments, state and lcoe needed to be added as features. On top of these, two other features were dervied as part of the calculation to determine the generated energy. These are as follows:\n\nArray Area, where \\(c\\) is capacity, \\(I\\) is the solar irradiance and \\(c_f\\) is the capacity factor.\n\n\n\\(A = \\frac{24c}{Ic_f}\\)\nWe multiply by 24 because \\(I\\) is in units of \\(kWh/m^2/day\\) and we want it in units of \\(kWh/m^2\\) to ensure we end up with an area as the result.\n\n\nAvailable Solar Resource, where \\(I\\) is the solar irradiance and \\(A\\) is the array area.\n\n\n\\(P = \\frac{IA}{24*1000}\\)\nThe 24 serves the same purpose as before, but the 1000 here changes the units from \\(kWh\\) to \\(MWh\\) to stay consistent all results.\n\nWith these, an equation for generated energy, \\(J\\) can be derived, where \\(P\\) is the available solar resource, \\(h\\) is the number of hours in a year, \\(c_f\\) is the capacity factor, and \\(q\\) is the system losses, which is assumed to be 14%:\n\n\\(J = P h  c_f  q\\)\n\nSame as the wind data, calculating the cost using the LCOE is very simple. A lifespan of 20 years is used again for consistency:\n\n\\(C = Jlt\\)\n\nThe chain of calculations incorporate more of the geospatial data, which exemplifies the purpose of the research project much more than what the old data had, even with clustering. Again, it allows the model to do its best at finding the relationship, compared to just recognizing a direct proportion like before. The resulting solar dataset looks like this:\n\n\n\n\n\n\n\n\n\n\nid\nlat\nlong\nstate\nfarm_type\nirradiance\nlcoe\ncapacity\ncapacity_factor\narray_area\navailable_solar_resource\ngenerated_energy\ncost\n\n\n\n\n0\n0\n25.896492\n-97.460358\nTexas\nlarge_community\n5.634079\n39\n5.00\n0.235\n90633.862770\n21.276596\n6132.00\n4782960.0\n\n\n1\n1\n26.032654\n-97.738098\nTexas\nsmall_utility\n5.616413\n39\n5.00\n0.234\n91307.484990\n21.367521\n6132.00\n4782960.0\n\n\n2\n2\n26.059063\n-97.208252\nTexas\nsmall_community\n5.746738\n39\n0.15\n0.239\n2621.097459\n0.627615\n183.96\n143488.8\n\n\n3\n3\n26.078449\n-98.073364\nTexas\nsmall_utility\n5.742196\n39\n5.00\n0.239\n87439.036330\n20.920502\n6132.00\n4782960.0\n\n\n4\n4\n26.143227\n-98.311340\nTexas\nsmall_utility\n5.817187\n39\n5.00\n0.242\n85241.850210\n20.661157\n6132.00\n4782960.0\n\n\n\n\n\n\n\nSource: Data Preview\nThis dataset is also available to be accessed and downloaded here."
  },
  {
    "objectID": "data.html#the-old-data",
    "href": "data.html#the-old-data",
    "title": "A Look at the Data",
    "section": "",
    "text": "Both the wind and solar data used in this project orginally come from The National Renewable Energy Laboratory (NREL). The data comes with many attributes that are crucial to the analysis this project seeks to conduct, however, there are still pieces missing to truly acheive the full picture. Regardless, compared to other publically available datasets, these were the best suited for the job, and offered a good starting point.\n\n\nThe original datasets came with some basic attributes:\n\nlongitude\nlatitude\nwind speed\nsolar irradiance\ncapacity\ncapacity factor\n\nThis, at first, is not enough data to begin predicting for energy generation and cost. For this, actual data on energy generation and cost is needed. With what was provided, these could be calculated. To start, a few simple calculations were used to find the energy and cost values desired. The attribute capacity denotes how much energy a certain technology can produce under ideal conditions. Capacity factor denotes what fraction of the technology’s capacity is produced. With this, a simple estimate for energy generation can be calculated by multiplying both values together. For cost, many estimates exist that outline how much a technology costs per watt of installed capacity. Using these estimates, and multiplying by capacity, a value for cost can be aquired. This produced two datasets that took this shape:\n\n\n\n\n\n\n\n\n\n\n\n\nid\nlat\nlong\nwind_speed\nfarm_type\ncapacity\ncapacity_factor\npower_generation\nestimated_cost\n\n\n\n\n0\n0\n23.510410\n-117.147260\n6.07\noffshore\n16\n0.169\n23687.04\n20800000\n\n\n1\n1\n24.007446\n-93.946777\n7.43\noffshore\n16\n0.302\n42328.32\n20800000\n\n\n2\n2\n25.069138\n-97.482483\n8.19\noffshore\n16\n0.375\n52560.00\n20800000\n\n\n3\n3\n25.069443\n-97.463135\n8.19\noffshore\n16\n0.375\n52560.00\n20800000\n\n\n4\n4\n25.069763\n-97.443756\n8.19\noffshore\n16\n0.376\n52700.16\n20800000\n\n\n\n\n\n\n\nSource: Data Preview\n\n\n\n\n\n\n\n\n\n\n\n\n\nid\nlat\nlong\nirradiance\nfarm_type\ncapacity\ncapacity_factor\npower_generation\nestimated_cost\n\n\n\n\n0\n0\n25.896492\n-97.460358\n5.634079\nlarge_community\n5.00\n0.235\n10282.193270\n13300000\n\n\n1\n1\n26.032654\n-97.738098\n5.616413\nsmall_utility\n5.00\n0.234\n10249.953070\n13300000\n\n\n2\n2\n26.059063\n-97.208252\n5.746738\nsmall_community\n0.15\n0.239\n314.633929\n399000\n\n\n3\n3\n26.078449\n-98.073364\n5.742196\nsmall_utility\n5.00\n0.239\n10479.506980\n13300000\n\n\n4\n4\n26.143227\n-98.311340\n5.817187\nsmall_utility\n5.00\n0.242\n10616.365970\n13300000\n\n\n\n\n\n\n\nSource: Data Preview\nThe rough and simplistic nature of these estimates are generally okay as the concern of this project is to determine how well machine learning algorithms predict values, and not the correctness and integrity of the values themselves. Nonetheless, issues still appeared because of this. When training and testing the Random Forest Regressor, a feature importance graph was used to determine which attributes are the most important. This can also give insights into how the variables are used by other models as well. When running on the old wind data, the graph indicated one variable was dominating the dataset.\n\n\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\nSource: Old Random Forest Model\n\n\n\nFeature Importances\n----------------------------\nlat: 1.7415146179729832e-09\nlong: 4.556724073707158e-09\nwind_speed: 2.5874951940190983e-08\ncapacity_factor: 0.0005676720796435423\ncapacity: 99.99943229574717\n\n\nSource: Old Random Forest Model\nOut of all of the features, capacity was shown to have the highest importance. This makes sense as both calculations are made up of direct proportions that scale based on capacity. This then indicates that the issue is not Random Forest exclusive, as this bias is present in the dataset, and not in how the algorithm interprets the dataset. Changes had to be implemeneted to remove this bias, which included adding more features and using more in-depth calculations to derive the features to be predicted. These are covered in The New Data.\n\n\n\n\nThe initial direction of this project was to look specifically into clustering techniques and cluster analysis. This process consists of grouping similar data into a specified number of clusters. When considering the geospatial data used for this project, clustering would be used to abstract coordinates in the form of longitude and latitude into a single value, a cluster ID. The cluster ID’s would then represent the other features of the data point, allowing for predictions of other features to be made based off of a given cluster ID or coordinate location. The main two steps for performing the clustering is breifly outlined below:\n\nDetermine the number of optimal clusters for the dataset.\n\nTo do this, you just need to cluster the data with varying cluster numbers, score them, and graph the scores by the number of clusters and determine the point at which gains start to diminish.\n\n\n\n\n\n\n\n\n\nFigure 2\n\n\n\n\n\nSource: Data Clustering\n\nCluster the data and plot the results\n\nWith the optimal number of clusters (or any desired number), the data can be clustered, with each data point given a cluster ID.\n\n\n\n\n\n\n\n\n\n\nlat\nlong\ncluster_label\n\n\n\n\n0\n23.510410\n-117.147260\n7\n\n\n1\n24.007446\n-93.946777\n6\n\n\n2\n25.069138\n-97.482483\n6\n\n\n3\n25.069443\n-97.463135\n6\n\n\n4\n25.069763\n-97.443756\n6\n\n\n\n\n\n\n\nSource: Data Clustering\nNow that clusters are generated, they can be plotted and visualized.\n\n\n\n\n\n\n\n\n\nFigure 3\n\n\n\n\n\nSource: Data Clustering\nThis not only shows the shape and dimensions of the data, but it also gives insights into how many clusters are suitable for the task. The scale of the data makes the number of optimal clusters here a bit ambiguous. Although around 20 seems to be the best, 20 clusters does not seem to represent the nuances of how geospatial data like wind speed and solar raditation changes throughout the country. This seems to indicate that this approach is a bit unreliable in that regard and could introduce more bias into the data and models.\nAdditionally, the clustering could also help increase the performance of the algorithms by lowering the number of input parameters. Simplifying the inputs allows the models to interpret the data easier, leading to better predictions. The issues described in the structure and make-up section further examplified this potential benefit. But for those same reasons, clustering ended up not being an ideal pathway forward. Not only would refactoring the data to remove the bias negate the benefits of clustering in the long run, but clustering also ends up become computationally expensive and tedious to implement and analyze given the nature of the data. For these reasons it was discarded as an aspect of the project."
  },
  {
    "objectID": "data.html#the-new-data",
    "href": "data.html#the-new-data",
    "title": "A Look at the Data",
    "section": "",
    "text": "To overcome the issues outlined above, the datasets were both refactored heavily to remove the bias present. This fixed structural issues, but also allowed for in-depth analysis of mahcine learning models without the time and efficiency overheads that would be present if clustering remained a crucial piece of the project. The process and results of refactoring both of the datasets are outlined below:\n\n\nTo reduce the bias in the wind dataset, new features were added and a new equation was used that incorporated more features than just capacity to ensure a wider range of importance across the board. Two new features were added:\n\nState - the state that the latitude and longitude coordinates are within.\nLevelized Cost of Energy (LCOE) - the average net cost of electricity generation for a generator over its lifetime.\n\nBoth of these features gave way for more inclusive calculations to be used for both energy generation and cost. The updated method to find the energy generation, \\(J\\), for a given wind farm uses the following equation where \\(c\\) is capacity, \\(\\rho\\) is the density of air, \\(A\\) is the swept area of the wind turbine, \\(v\\) is the wind speed, \\(h\\) is the number of hours in a year, and \\(c_f\\) is capacity factor:\n\n\\(J = \\frac{c}{2}\\left( \\frac{1}{2}\\rho Av^3\\right)h c_f\\)\nSome values here are assumed constants: \\(\\rho = 1.225 kg/m^3\\), \\(A = 7854 m^2\\), \\(h = 8760hrs\\)\n\nAlso, this equation was split at certain parts to increase the number of features, to aide the model in being able to track the relationships better. The splits added the features available_wind_power and available_energy.\nCalculating the cost using LCOE is very simple. A technology’s LCOE is measured in dollars per watt-hour of energy generated. The only other piece needed is the lifespan of the technology. For this project, a 20 year lifespan is assumed for all wind turbines. This results in this equation where \\(J\\) is generated energy, \\(l\\) is the LCOE of the technology in the state, and \\(t\\) is the lifespan of the technology:\n\n\\(C = Jlt\\)\n\nThese equations incorporate crucial pieces of geospatial data that were not present in the previous calculation. It also adds other assumed constants, which add complexity to the calculation and obscure the relationships a bit, giving the model more agency to work out the connections. In the end, it results in a dataset that looks like this:\n\n\n\n\n\n\n\n\n\n\nid\nlat\nlong\nstate\nfarm_type\nwind_speed\nlcoe\ncapacity\ncapacity_factor\navailable_wind_power\navailable_energy\ngenerated_energy\ncost\n\n\n\n\n0\n0\n25.896492\n-97.460358\nTexas\nonshore\n7.46\n31\n2\n0.433\n1.997163\n17495.14630\n7575.398348\n4.696747e+06\n\n\n1\n1\n26.032654\n-97.738098\nTexas\nonshore\n7.45\n31\n10\n0.414\n9.945710\n87124.42376\n36069.511440\n2.236310e+07\n\n\n2\n2\n26.059063\n-97.208252\nTexas\nonshore\n8.18\n31\n2\n0.506\n2.633037\n23065.40088\n11671.092850\n7.236078e+06\n\n\n3\n3\n26.078449\n-98.073364\nTexas\nonshore\n7.17\n31\n16\n0.363\n14.185493\n124264.92160\n45108.166540\n2.796706e+07\n\n\n4\n4\n26.143227\n-98.311340\nTexas\nonshore\n7.06\n31\n16\n0.358\n13.542570\n118632.91080\n42470.582050\n2.633176e+07\n\n\n\n\n\n\n\nSource: Data Preview\nThis dataset can be accessed and downloaded from here.\n\n\n\nSimilar to the wind dataset, bias was reduced by adding more features and using a new equation which incorporated more features. Like the wind data, to make these adjustments, state and lcoe needed to be added as features. On top of these, two other features were dervied as part of the calculation to determine the generated energy. These are as follows:\n\nArray Area, where \\(c\\) is capacity, \\(I\\) is the solar irradiance and \\(c_f\\) is the capacity factor.\n\n\n\\(A = \\frac{24c}{Ic_f}\\)\nWe multiply by 24 because \\(I\\) is in units of \\(kWh/m^2/day\\) and we want it in units of \\(kWh/m^2\\) to ensure we end up with an area as the result.\n\n\nAvailable Solar Resource, where \\(I\\) is the solar irradiance and \\(A\\) is the array area.\n\n\n\\(P = \\frac{IA}{24*1000}\\)\nThe 24 serves the same purpose as before, but the 1000 here changes the units from \\(kWh\\) to \\(MWh\\) to stay consistent all results.\n\nWith these, an equation for generated energy, \\(J\\) can be derived, where \\(P\\) is the available solar resource, \\(h\\) is the number of hours in a year, \\(c_f\\) is the capacity factor, and \\(q\\) is the system losses, which is assumed to be 14%:\n\n\\(J = P h  c_f  q\\)\n\nSame as the wind data, calculating the cost using the LCOE is very simple. A lifespan of 20 years is used again for consistency:\n\n\\(C = Jlt\\)\n\nThe chain of calculations incorporate more of the geospatial data, which exemplifies the purpose of the research project much more than what the old data had, even with clustering. Again, it allows the model to do its best at finding the relationship, compared to just recognizing a direct proportion like before. The resulting solar dataset looks like this:\n\n\n\n\n\n\n\n\n\n\nid\nlat\nlong\nstate\nfarm_type\nirradiance\nlcoe\ncapacity\ncapacity_factor\narray_area\navailable_solar_resource\ngenerated_energy\ncost\n\n\n\n\n0\n0\n25.896492\n-97.460358\nTexas\nlarge_community\n5.634079\n39\n5.00\n0.235\n90633.862770\n21.276596\n6132.00\n4782960.0\n\n\n1\n1\n26.032654\n-97.738098\nTexas\nsmall_utility\n5.616413\n39\n5.00\n0.234\n91307.484990\n21.367521\n6132.00\n4782960.0\n\n\n2\n2\n26.059063\n-97.208252\nTexas\nsmall_community\n5.746738\n39\n0.15\n0.239\n2621.097459\n0.627615\n183.96\n143488.8\n\n\n3\n3\n26.078449\n-98.073364\nTexas\nsmall_utility\n5.742196\n39\n5.00\n0.239\n87439.036330\n20.920502\n6132.00\n4782960.0\n\n\n4\n4\n26.143227\n-98.311340\nTexas\nsmall_utility\n5.817187\n39\n5.00\n0.242\n85241.850210\n20.661157\n6132.00\n4782960.0\n\n\n\n\n\n\n\nSource: Data Preview\nThis dataset is also available to be accessed and downloaded here."
  },
  {
    "objectID": "rf.html",
    "href": "rf.html",
    "title": "Random Forest Regression on Geospatial Data",
    "section": "",
    "text": "The Random Forest model is an simple, easy to use model that offers good results on a consistent basis for a wide range of applications. One of the areas that it is known to perform quite well in, is geospatial applications. Because of this, there is no doubt it was one of the algorithms chosen for this projects’ analysis. The “regressor” in Random Forest Regressor, stems from the use of strictly numeric data points in the project, which is analyzed most effectively through regressions. Below, the steps to use the Random Forest Regressor model from sklearn on the datasets in breifly outlined. To fill in those blanks, the relative notebooks are linked on the side.\n\n\n\n\nThe first step when performing any kind of machine learning problem or analysis is to read in the data, make alterations to it, and select features for training and testing. For this showcase, we will look at the wind data:\n\n\n\n\n\n\n\n\n\n\nid\nlat\nlong\nstate\nfarm_type\nwind_speed\nlcoe\ncapacity\ncapacity_factor\navailable_wind_power\navailable_energy\ngenerated_energy\ncost\n\n\n\n\n0\n0\n25.896492\n-97.460358\nTexas\nonshore\n7.46\n31\n2\n0.433\n1.997163\n17495.14630\n7575.398348\n4.696747e+06\n\n\n1\n1\n26.032654\n-97.738098\nTexas\nonshore\n7.45\n31\n10\n0.414\n9.945710\n87124.42376\n36069.511440\n2.236310e+07\n\n\n2\n2\n26.059063\n-97.208252\nTexas\nonshore\n8.18\n31\n2\n0.506\n2.633037\n23065.40088\n11671.092850\n7.236078e+06\n\n\n3\n3\n26.078449\n-98.073364\nTexas\nonshore\n7.17\n31\n16\n0.363\n14.185493\n124264.92160\n45108.166540\n2.796706e+07\n\n\n4\n4\n26.143227\n-98.311340\nTexas\nonshore\n7.06\n31\n16\n0.358\n13.542570\n118632.91080\n42470.582050\n2.633176e+07\n\n\n\n\n\n\n\nSource: Data Preview\nThe dataset as it is, potentially has a lot of bias due to its structure and ordering. Although a human may not be able to see a pattern in the order the way the data as been recorded, a machine learning model is very sensitive to nuances like this. To reduce this being a factor, the dataset must be shuffled. A method from the Python package pandas can do this very easily, that method being sample(). Once it is used, the dataset ends up looking like this:\n\n\n\n\n\n\n\n\n\n\nid\nlat\nlong\nstate\nfarm_type\nwind_speed\nlcoe\ncapacity\ncapacity_factor\navailable_wind_power\navailable_energy\ngenerated_energy\ncost\n\n\n\n\n79590\n79590\n41.837624\n-117.217148\nNevada\nonshore\n6.79\n52\n16\n0.309\n12.047482\n105535.9457\n32610.60721\n33915031.49\n\n\n63264\n63264\n39.696823\n-120.172119\nCalifornia\nonshore\n6.93\n47\n16\n0.349\n12.808158\n112199.4652\n39157.61336\n36808156.56\n\n\n67794\n67794\n42.508434\n-105.420929\nWyoming\nonshore\n7.09\n30\n16\n0.326\n13.715943\n120151.6637\n39169.44236\n23501665.42\n\n\n76743\n76743\n43.585987\n-92.464874\nMinnesota\nonshore\n7.76\n32\n16\n0.489\n17.983414\n157534.7060\n77034.47126\n49302061.60\n\n\n80060\n80060\n43.905441\n-92.548767\nMinnesota\nonshore\n7.64\n32\n14\n0.432\n15.016721\n131546.4741\n56828.07680\n36369969.15\n\n\n\n\n\n\n\nSource: Random Forest Regression Process and Analysis for Wind Data\nWith the data shuffled, we can now ensure that the training and testing splits have as little bias as possible, from an ordering perspective. Two different arrays must be made for each split, those being X, the inputs, and y, the outputs, or features to be predicted. For this project, we are interested in determining if a machine learning model is effective when only given locational data, and as little extra information as possible. So for our X variables, we chose lat, long, and capacity. For the y, generated_energy and cost were used, since these are the values we want to predict. The idea is that a hypothetical user should only need to input their location, and how big they want the wind turbine/farm to be, if they want predictions.\nX = df.loc[:, ['lat','long','capacity']]\ny = df.loc[:, ['generated_energy','cost']]\n\nX_train = X[:100000]\nX_test = X[100000:]\ny_train = y[:100000]\ny_test = y[100000:]\n\nNotice that we are using two targets, this is because we are taking advantage of multioutput regression functionality. This saves on time and computational costs by creating one model that can predict two targets with one set of features.\n\nWith shuffled traiing and testing splits, some changes must be made to the data to ensure it is easier for the model to process. Many machine learning models prefer having smaller numbers, ideally numbers between [1,-1]. From the dataset above, this is clearly not the case. To get close to this ideal, a scaler is used. A scaler will take the entire dataset, and apply a transformation to every feature, making the numbers smaller, and easier for a model to work with, without losing the meaning the original data had. For this project, sklearn’s StandardScaler was used. Note: The scaler is only used on the inputs, not on the outputs. It would not change the results, but it would supply an illusion that the model is performing better.\n\n\n\narray([[ 0.29976876, -1.55213354,  0.51397118],\n       [-0.19081527, -1.80102981,  0.51397118],\n       [ 0.45349097, -0.55854175,  0.51397118],\n       ...,\n       [-0.98926974, -0.04632361,  0.51397118],\n       [ 1.01246158,  2.31043674, -0.67408559],\n       [-0.93654137,  1.82255592,  0.51397118]])\n\n\nSource: Random Forest Regression Process and Analysis for Wind Data\nNow, the data is ready to be used to train a Random Forest Regressor model.\n\n\n\nThis research is interested in determining if simple machine learning models can effectively predict renewable energy array parameters. To exaggerate this point, the models were used in the most out-of-the-box way possible, keeping things very simple. To train the model, the training data is passed into the Random Forest Regressor:\nreg = RandomForestRegressor()\nreg.fit(X_train, y_train)\nThis ends up creating a large amount of individual decision trees, making up a forest. Each tree uses the input features as decision making points, splitting nodes in the tree based on how well a feature is contributing towards making better predictions. Because of the scale of the data, the trees are very large, but the general structure of the first few nodes looks like this:\n\n\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\nSource: Random Forest Regression Process and Analysis for Wind Data\nWith a trained model, predictions can be made using the predict() method. Below are some predicted values compared to the true values.\n\n\n\nPredictions\n----------------------\npredicted energy: 83754.58  actual energy: 83847.86 predicted cost: 53602934.30 actual cost: 53662631.64\npredicted energy: 71218.08  actual energy: 72733.57 predicted cost: 45579569.00 actual cost: 46549485.59\npredicted energy: 12278.47  actual energy: 12532.50 predicted cost: 7367082.12  actual cost: 7519499.96\n\n\nSource: Random Forest Regression Process and Analysis for Wind Data\nThe values are fairly close, especially when considering how little information the model is using to make the predictions. This indicates that there is some potential that general location-based information is enough to estimate the energy generation and cost of a wind turbine/farm.\n\n\n\n\nThere are many ways to evaluate the performace of a model. Some of these are model dependent, like feature importance for a Random Forest. Others can be done to any model, like reporting metrics, or performing k-fold cross validation. Outlined below, are the strategies used to evaluate the performance of the Random Forest Regressor used in this project.\n\n\nTo evaluate the machine learning models, three metrics, available through sklearn, were chosen.\n\nR2-score (R2) - a goodness-of-fit metric that indicates how well a plotted curve represents the data.\nRoot Mean Squared Error (RMSE) - an error metric that explicitly states the average distance between a predicted value and its true counterpart.\nMean Absolute Percentage Error (MAPE) - a goodness-of-fit metric that indicates the average percent error a prediction has relative to the true values.\n\nR2 and MAPE were chosen because they are very scale-independent, meaning the difference in size of the data’s features and outliers have less of an effect on the score. The data has many outliers, and the features values range drastically in size, sometimes by many orders of magnitude. Scale-independent metrics help to isolate these edge cases and provide scoring that is relative to the majority of the dataset.\nRMSE was chosen because, unlike R2 and MAPE, it is very scale-dependent. Utilizing both types of metrics ensures that the full picture is uncovered, giving a better overall summary of performance. Even though the scale of the data and the outliers may abstract the meaning of the score somewhat, the scale can be used to help explain why the metric appears the way it does. In the end, it still provides valuable insights into the performance that could indicate pathways for improvement in the future.\nA single report of metrics for an isolated training and testing session looks like this:\n\n\n\nMetric  Score\n-----------------------\nr2  [0.91837919 0.886822  ]\nrmse    [   9016.1235774  6597654.69852586]\nmape    [0.12685824 0.12691037]\n\n\nSource: Random Forest Regression Process and Analysis for Wind Data\n\nThe metrics are separated for each target variable, the values on the left are for generated_energy predictions and the values on the right are for cost predictions.\n\nR2 values around .90 indicate desireable results. This means that 90% of the variance in the dataset can be explained by the model, meaning it is fitting the data well. The MAPE values rienforce this idea too. While MAPE values below 10% would be the most ideal, a MAPE of 13% indicates predictions are on average 13% off of what they should be. This is generally considered “good”.\nThe RMSE is where things get tricky. Individually, they are not too awful. Although they look large, they are inflated due to the scale of the data. When considering that the majority of the data for generated energy is in the tens of thousands, and for cost it is in the tens of millions, the ratio of the RMSE to this “median” value can be roughly approximated to around .30, or 30% for both targets. For a metric that is not best suited for a dataset of this type, 30% also can indicate promising results. Even though it is more than twice the MAPE, this is to be expected because of the scale issues mentioned prior. In the end, it highlights the issue posed by the dataset, but also can somewhat reinforce the idea that the model is performing well, if examined deep enough.\n\n\n\nIn a Random Forest, the input features end up being “ranked” by importance. This means that some features are used to determine how the tree splits more than others. A higher importance indicates that a feature is being used more often, while a lower importance indicates the opposite. When assessing a Random Forest, it is nice to see an even split of importance across all features. This would indicate that all of the features are being used equally to get to predictions. This not only ensures the model is functioning properly, but it also ensures that the dataset is not skewed towards a single feature.\nA plot of the feature importances, and their respective values are shown below:\n\n\n\n\n\n\n\n\n\nFigure 2\n\n\n\n\n\nSource: Random Forest Regression Process and Analysis for Wind Data\n\n\n\nImportances\n----------------------\ncapacity: 20.135246241505772\nlat: 35.00933261524246\nlong: 44.855421143251775\n\n\nSource: Random Forest Regression Process and Analysis for Wind Data\nWhile it is not an even split, each feature has an importance that is significant when regarding the creation of the model. This indicates that the model is functioning fairly well with how it is using the data, and it even goes so far as to reinforce that the dataset is construced in a meaningful and unbiased way. All of this points to the model being effective at making trustworthy predictions.\n\n\n\nThe last piece of assessment comes from k-fold cross validation. K-fold cross validation consists of splitting up the dataset into k folds, and using those folds for training and testing. Each fold produces a trained model that then has metrics taken from it, in this case it is the same metrics listed above. The end goal being to obtain averages for all of the desired metrics over the entire dataset. Even though we shuffled the dataset, some of the data is not being used for training. K-fold cross validation ensures that all of the data is being used for both training and testing at some point, resulting in more accurate reporting of metrics.\nFor this project, 10 folds were used. The results of running k-fold cross validation on the wind dataset is shown below.\n\n\n\n10-Fold Cross Validation Scores\n----------------------------------------------------\nR2 Average: 0.9109908237527048\nRMSE Average: 3181739.2057383326\nMAPE Average: 0.13390596472645255\n\n\n\n\n\n\n\n\n\nfit_time\nscore_time\ntest_r2\ntest_rmse\ntest_mape\n\n\n\n\n0\n35.631838\n0.412091\n0.908636\n3.244508e+06\n0.126463\n\n\n1\n35.085633\n0.407737\n0.909902\n3.194235e+06\n0.134273\n\n\n2\n34.784758\n0.409132\n0.912724\n3.128678e+06\n0.129694\n\n\n3\n34.819360\n0.401673\n0.908216\n3.253428e+06\n0.126229\n\n\n4\n34.879103\n0.404808\n0.907344\n3.241619e+06\n0.137367\n\n\n5\n34.481580\n0.417363\n0.915569\n3.113150e+06\n0.137573\n\n\n6\n35.357341\n0.434344\n0.908085\n3.232867e+06\n0.148030\n\n\n7\n37.669082\n0.456003\n0.915380\n3.138264e+06\n0.137533\n\n\n8\n37.000147\n0.439912\n0.913334\n3.138594e+06\n0.128061\n\n\n9\n34.930129\n0.409387\n0.910719\n3.132047e+06\n0.133837\n\n\n\n\n\n\n\nSource: Random Forest Regression Process and Analysis for Wind Data\nK-fold cross validation through sklearn does not support multioutput. Because of this, the metrics for both targets are averaged together, resulting in one metric that defines the model’s overall performance. This is okay for R2 and MAPE, as they are similar enough and scale-independent, so little information is lost or abstracted. RMSE, however, becomes slightly less meaningfull when averaged due to the difference in scale between generated_energy and cost. Averaging the separate RMSE’s from a single report results in an average RMSE of 3,137,778.11. Comparing this to the average RMSE from cross validation, they are fairly similar. It can then be assumed that the individual RMSE’s would be around the same, indicating that the averages for then entire dataset are still within reasonable bounds. A similar conclusion can be drawn regarding R2 and MAPE. These values are within the same bounds of acceptance as they were in the metrics section, indicating good results.\n\n\n\n\nThe solar data is not, and will, not be covered in detail like the wind data was above. It was concluded that the solar data is insufficient for the project’s goals. The metrics that come from a model trained on solar data indicate more than just poor results. It is omitted to reduce confusion and bring to light the more impactful results of this experiment.\n\n\n\nMetric  Score\n-----------------------\nr2  [1.         0.99973199]\nrmse    [1.84203151e-12 1.00424139e+07]\nmape    [9.85642916e-16 4.44841521e-03]\n\n\nSource: Random Forest Regression Process and Analysis for Solar Data\nNumbers that look like this are intrinsic of bad models or bad data. In this case, it is bad data. The issue stems from what data was available publically and feasible to work with. Many gaps needed to be filled in, and not enough data was available to fill these gaps in, in a way that did not comprimise the dataset in the end. The notebook is still available to view for purposes of experiment replication and validation."
  },
  {
    "objectID": "rf.html#getting-a-trained-model",
    "href": "rf.html#getting-a-trained-model",
    "title": "Random Forest Regression on Geospatial Data",
    "section": "",
    "text": "The first step when performing any kind of machine learning problem or analysis is to read in the data, make alterations to it, and select features for training and testing. For this showcase, we will look at the wind data:\n\n\n\n\n\n\n\n\n\n\nid\nlat\nlong\nstate\nfarm_type\nwind_speed\nlcoe\ncapacity\ncapacity_factor\navailable_wind_power\navailable_energy\ngenerated_energy\ncost\n\n\n\n\n0\n0\n25.896492\n-97.460358\nTexas\nonshore\n7.46\n31\n2\n0.433\n1.997163\n17495.14630\n7575.398348\n4.696747e+06\n\n\n1\n1\n26.032654\n-97.738098\nTexas\nonshore\n7.45\n31\n10\n0.414\n9.945710\n87124.42376\n36069.511440\n2.236310e+07\n\n\n2\n2\n26.059063\n-97.208252\nTexas\nonshore\n8.18\n31\n2\n0.506\n2.633037\n23065.40088\n11671.092850\n7.236078e+06\n\n\n3\n3\n26.078449\n-98.073364\nTexas\nonshore\n7.17\n31\n16\n0.363\n14.185493\n124264.92160\n45108.166540\n2.796706e+07\n\n\n4\n4\n26.143227\n-98.311340\nTexas\nonshore\n7.06\n31\n16\n0.358\n13.542570\n118632.91080\n42470.582050\n2.633176e+07\n\n\n\n\n\n\n\nSource: Data Preview\nThe dataset as it is, potentially has a lot of bias due to its structure and ordering. Although a human may not be able to see a pattern in the order the way the data as been recorded, a machine learning model is very sensitive to nuances like this. To reduce this being a factor, the dataset must be shuffled. A method from the Python package pandas can do this very easily, that method being sample(). Once it is used, the dataset ends up looking like this:\n\n\n\n\n\n\n\n\n\n\nid\nlat\nlong\nstate\nfarm_type\nwind_speed\nlcoe\ncapacity\ncapacity_factor\navailable_wind_power\navailable_energy\ngenerated_energy\ncost\n\n\n\n\n79590\n79590\n41.837624\n-117.217148\nNevada\nonshore\n6.79\n52\n16\n0.309\n12.047482\n105535.9457\n32610.60721\n33915031.49\n\n\n63264\n63264\n39.696823\n-120.172119\nCalifornia\nonshore\n6.93\n47\n16\n0.349\n12.808158\n112199.4652\n39157.61336\n36808156.56\n\n\n67794\n67794\n42.508434\n-105.420929\nWyoming\nonshore\n7.09\n30\n16\n0.326\n13.715943\n120151.6637\n39169.44236\n23501665.42\n\n\n76743\n76743\n43.585987\n-92.464874\nMinnesota\nonshore\n7.76\n32\n16\n0.489\n17.983414\n157534.7060\n77034.47126\n49302061.60\n\n\n80060\n80060\n43.905441\n-92.548767\nMinnesota\nonshore\n7.64\n32\n14\n0.432\n15.016721\n131546.4741\n56828.07680\n36369969.15\n\n\n\n\n\n\n\nSource: Random Forest Regression Process and Analysis for Wind Data\nWith the data shuffled, we can now ensure that the training and testing splits have as little bias as possible, from an ordering perspective. Two different arrays must be made for each split, those being X, the inputs, and y, the outputs, or features to be predicted. For this project, we are interested in determining if a machine learning model is effective when only given locational data, and as little extra information as possible. So for our X variables, we chose lat, long, and capacity. For the y, generated_energy and cost were used, since these are the values we want to predict. The idea is that a hypothetical user should only need to input their location, and how big they want the wind turbine/farm to be, if they want predictions.\nX = df.loc[:, ['lat','long','capacity']]\ny = df.loc[:, ['generated_energy','cost']]\n\nX_train = X[:100000]\nX_test = X[100000:]\ny_train = y[:100000]\ny_test = y[100000:]\n\nNotice that we are using two targets, this is because we are taking advantage of multioutput regression functionality. This saves on time and computational costs by creating one model that can predict two targets with one set of features.\n\nWith shuffled traiing and testing splits, some changes must be made to the data to ensure it is easier for the model to process. Many machine learning models prefer having smaller numbers, ideally numbers between [1,-1]. From the dataset above, this is clearly not the case. To get close to this ideal, a scaler is used. A scaler will take the entire dataset, and apply a transformation to every feature, making the numbers smaller, and easier for a model to work with, without losing the meaning the original data had. For this project, sklearn’s StandardScaler was used. Note: The scaler is only used on the inputs, not on the outputs. It would not change the results, but it would supply an illusion that the model is performing better.\n\n\n\narray([[ 0.29976876, -1.55213354,  0.51397118],\n       [-0.19081527, -1.80102981,  0.51397118],\n       [ 0.45349097, -0.55854175,  0.51397118],\n       ...,\n       [-0.98926974, -0.04632361,  0.51397118],\n       [ 1.01246158,  2.31043674, -0.67408559],\n       [-0.93654137,  1.82255592,  0.51397118]])\n\n\nSource: Random Forest Regression Process and Analysis for Wind Data\nNow, the data is ready to be used to train a Random Forest Regressor model.\n\n\n\nThis research is interested in determining if simple machine learning models can effectively predict renewable energy array parameters. To exaggerate this point, the models were used in the most out-of-the-box way possible, keeping things very simple. To train the model, the training data is passed into the Random Forest Regressor:\nreg = RandomForestRegressor()\nreg.fit(X_train, y_train)\nThis ends up creating a large amount of individual decision trees, making up a forest. Each tree uses the input features as decision making points, splitting nodes in the tree based on how well a feature is contributing towards making better predictions. Because of the scale of the data, the trees are very large, but the general structure of the first few nodes looks like this:\n\n\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\nSource: Random Forest Regression Process and Analysis for Wind Data\nWith a trained model, predictions can be made using the predict() method. Below are some predicted values compared to the true values.\n\n\n\nPredictions\n----------------------\npredicted energy: 83754.58  actual energy: 83847.86 predicted cost: 53602934.30 actual cost: 53662631.64\npredicted energy: 71218.08  actual energy: 72733.57 predicted cost: 45579569.00 actual cost: 46549485.59\npredicted energy: 12278.47  actual energy: 12532.50 predicted cost: 7367082.12  actual cost: 7519499.96\n\n\nSource: Random Forest Regression Process and Analysis for Wind Data\nThe values are fairly close, especially when considering how little information the model is using to make the predictions. This indicates that there is some potential that general location-based information is enough to estimate the energy generation and cost of a wind turbine/farm."
  },
  {
    "objectID": "rf.html#analyzing-and-assesing-the-random-forest",
    "href": "rf.html#analyzing-and-assesing-the-random-forest",
    "title": "Random Forest Regression on Geospatial Data",
    "section": "",
    "text": "There are many ways to evaluate the performace of a model. Some of these are model dependent, like feature importance for a Random Forest. Others can be done to any model, like reporting metrics, or performing k-fold cross validation. Outlined below, are the strategies used to evaluate the performance of the Random Forest Regressor used in this project.\n\n\nTo evaluate the machine learning models, three metrics, available through sklearn, were chosen.\n\nR2-score (R2) - a goodness-of-fit metric that indicates how well a plotted curve represents the data.\nRoot Mean Squared Error (RMSE) - an error metric that explicitly states the average distance between a predicted value and its true counterpart.\nMean Absolute Percentage Error (MAPE) - a goodness-of-fit metric that indicates the average percent error a prediction has relative to the true values.\n\nR2 and MAPE were chosen because they are very scale-independent, meaning the difference in size of the data’s features and outliers have less of an effect on the score. The data has many outliers, and the features values range drastically in size, sometimes by many orders of magnitude. Scale-independent metrics help to isolate these edge cases and provide scoring that is relative to the majority of the dataset.\nRMSE was chosen because, unlike R2 and MAPE, it is very scale-dependent. Utilizing both types of metrics ensures that the full picture is uncovered, giving a better overall summary of performance. Even though the scale of the data and the outliers may abstract the meaning of the score somewhat, the scale can be used to help explain why the metric appears the way it does. In the end, it still provides valuable insights into the performance that could indicate pathways for improvement in the future.\nA single report of metrics for an isolated training and testing session looks like this:\n\n\n\nMetric  Score\n-----------------------\nr2  [0.91837919 0.886822  ]\nrmse    [   9016.1235774  6597654.69852586]\nmape    [0.12685824 0.12691037]\n\n\nSource: Random Forest Regression Process and Analysis for Wind Data\n\nThe metrics are separated for each target variable, the values on the left are for generated_energy predictions and the values on the right are for cost predictions.\n\nR2 values around .90 indicate desireable results. This means that 90% of the variance in the dataset can be explained by the model, meaning it is fitting the data well. The MAPE values rienforce this idea too. While MAPE values below 10% would be the most ideal, a MAPE of 13% indicates predictions are on average 13% off of what they should be. This is generally considered “good”.\nThe RMSE is where things get tricky. Individually, they are not too awful. Although they look large, they are inflated due to the scale of the data. When considering that the majority of the data for generated energy is in the tens of thousands, and for cost it is in the tens of millions, the ratio of the RMSE to this “median” value can be roughly approximated to around .30, or 30% for both targets. For a metric that is not best suited for a dataset of this type, 30% also can indicate promising results. Even though it is more than twice the MAPE, this is to be expected because of the scale issues mentioned prior. In the end, it highlights the issue posed by the dataset, but also can somewhat reinforce the idea that the model is performing well, if examined deep enough.\n\n\n\nIn a Random Forest, the input features end up being “ranked” by importance. This means that some features are used to determine how the tree splits more than others. A higher importance indicates that a feature is being used more often, while a lower importance indicates the opposite. When assessing a Random Forest, it is nice to see an even split of importance across all features. This would indicate that all of the features are being used equally to get to predictions. This not only ensures the model is functioning properly, but it also ensures that the dataset is not skewed towards a single feature.\nA plot of the feature importances, and their respective values are shown below:\n\n\n\n\n\n\n\n\n\nFigure 2\n\n\n\n\n\nSource: Random Forest Regression Process and Analysis for Wind Data\n\n\n\nImportances\n----------------------\ncapacity: 20.135246241505772\nlat: 35.00933261524246\nlong: 44.855421143251775\n\n\nSource: Random Forest Regression Process and Analysis for Wind Data\nWhile it is not an even split, each feature has an importance that is significant when regarding the creation of the model. This indicates that the model is functioning fairly well with how it is using the data, and it even goes so far as to reinforce that the dataset is construced in a meaningful and unbiased way. All of this points to the model being effective at making trustworthy predictions.\n\n\n\nThe last piece of assessment comes from k-fold cross validation. K-fold cross validation consists of splitting up the dataset into k folds, and using those folds for training and testing. Each fold produces a trained model that then has metrics taken from it, in this case it is the same metrics listed above. The end goal being to obtain averages for all of the desired metrics over the entire dataset. Even though we shuffled the dataset, some of the data is not being used for training. K-fold cross validation ensures that all of the data is being used for both training and testing at some point, resulting in more accurate reporting of metrics.\nFor this project, 10 folds were used. The results of running k-fold cross validation on the wind dataset is shown below.\n\n\n\n10-Fold Cross Validation Scores\n----------------------------------------------------\nR2 Average: 0.9109908237527048\nRMSE Average: 3181739.2057383326\nMAPE Average: 0.13390596472645255\n\n\n\n\n\n\n\n\n\nfit_time\nscore_time\ntest_r2\ntest_rmse\ntest_mape\n\n\n\n\n0\n35.631838\n0.412091\n0.908636\n3.244508e+06\n0.126463\n\n\n1\n35.085633\n0.407737\n0.909902\n3.194235e+06\n0.134273\n\n\n2\n34.784758\n0.409132\n0.912724\n3.128678e+06\n0.129694\n\n\n3\n34.819360\n0.401673\n0.908216\n3.253428e+06\n0.126229\n\n\n4\n34.879103\n0.404808\n0.907344\n3.241619e+06\n0.137367\n\n\n5\n34.481580\n0.417363\n0.915569\n3.113150e+06\n0.137573\n\n\n6\n35.357341\n0.434344\n0.908085\n3.232867e+06\n0.148030\n\n\n7\n37.669082\n0.456003\n0.915380\n3.138264e+06\n0.137533\n\n\n8\n37.000147\n0.439912\n0.913334\n3.138594e+06\n0.128061\n\n\n9\n34.930129\n0.409387\n0.910719\n3.132047e+06\n0.133837\n\n\n\n\n\n\n\nSource: Random Forest Regression Process and Analysis for Wind Data\nK-fold cross validation through sklearn does not support multioutput. Because of this, the metrics for both targets are averaged together, resulting in one metric that defines the model’s overall performance. This is okay for R2 and MAPE, as they are similar enough and scale-independent, so little information is lost or abstracted. RMSE, however, becomes slightly less meaningfull when averaged due to the difference in scale between generated_energy and cost. Averaging the separate RMSE’s from a single report results in an average RMSE of 3,137,778.11. Comparing this to the average RMSE from cross validation, they are fairly similar. It can then be assumed that the individual RMSE’s would be around the same, indicating that the averages for then entire dataset are still within reasonable bounds. A similar conclusion can be drawn regarding R2 and MAPE. These values are within the same bounds of acceptance as they were in the metrics section, indicating good results."
  },
  {
    "objectID": "2-rf-wind.html",
    "href": "2-rf-wind.html",
    "title": "Random Forest Regression Process and Analysis for Wind Data",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.legend_handler import HandlerLine2D\nimport sklearn.metrics as metrics\nfrom sklearn.model_selection import cross_validate, KFold\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import tree"
  },
  {
    "objectID": "2-rf-wind.html#imports",
    "href": "2-rf-wind.html#imports",
    "title": "Random Forest Regression Process and Analysis for Wind Data",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.legend_handler import HandlerLine2D\nimport sklearn.metrics as metrics\nfrom sklearn.model_selection import cross_validate, KFold\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import tree"
  },
  {
    "objectID": "2-rf-wind.html#data-preprocessing",
    "href": "2-rf-wind.html#data-preprocessing",
    "title": "Random Forest Regression Process and Analysis for Wind Data",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\nFirst, we read in the dataset.\n\ndf = pd.read_csv(\"../data/wind.csv\")\ndf.head(5)\n\n\n\n\n\n\n\n\nid\nlat\nlong\nstate\nfarm_type\nwind_speed\nlcoe\ncapacity\ncapacity_factor\navailable_wind_power\navailable_energy\ngenerated_energy\ncost\n\n\n\n\n0\n0\n25.896492\n-97.460358\nTexas\nonshore\n7.46\n31\n2\n0.433\n1.997163\n17495.14630\n7575.398348\n4.696747e+06\n\n\n1\n1\n26.032654\n-97.738098\nTexas\nonshore\n7.45\n31\n10\n0.414\n9.945710\n87124.42376\n36069.511440\n2.236310e+07\n\n\n2\n2\n26.059063\n-97.208252\nTexas\nonshore\n8.18\n31\n2\n0.506\n2.633037\n23065.40088\n11671.092850\n7.236078e+06\n\n\n3\n3\n26.078449\n-98.073364\nTexas\nonshore\n7.17\n31\n16\n0.363\n14.185493\n124264.92160\n45108.166540\n2.796706e+07\n\n\n4\n4\n26.143227\n-98.311340\nTexas\nonshore\n7.06\n31\n16\n0.358\n13.542570\n118632.91080\n42470.582050\n2.633176e+07\n\n\n\n\n\n\n\nNow, we must shuffle the datasets to reduce bias.\n\ndf = df.sample(frac=1)\ndf.head(5)\n\n\n\n\n\n\n\n\nid\nlat\nlong\nstate\nfarm_type\nwind_speed\nlcoe\ncapacity\ncapacity_factor\navailable_wind_power\navailable_energy\ngenerated_energy\ncost\n\n\n\n\n79590\n79590\n41.837624\n-117.217148\nNevada\nonshore\n6.79\n52\n16\n0.309\n12.047482\n105535.9457\n32610.60721\n33915031.49\n\n\n63264\n63264\n39.696823\n-120.172119\nCalifornia\nonshore\n6.93\n47\n16\n0.349\n12.808158\n112199.4652\n39157.61336\n36808156.56\n\n\n67794\n67794\n42.508434\n-105.420929\nWyoming\nonshore\n7.09\n30\n16\n0.326\n13.715943\n120151.6637\n39169.44236\n23501665.42\n\n\n76743\n76743\n43.585987\n-92.464874\nMinnesota\nonshore\n7.76\n32\n16\n0.489\n17.983414\n157534.7060\n77034.47126\n49302061.60\n\n\n80060\n80060\n43.905441\n-92.548767\nMinnesota\nonshore\n7.64\n32\n14\n0.432\n15.016721\n131546.4741\n56828.07680\n36369969.15\n\n\n\n\n\n\n\nLooking at each dataset, we can identify which variables we want to use for our models.\n\nX = df.loc[:, ['lat','long','capacity']]\ny = df.loc[:, ['generated_energy','cost']]\n\nNow we split into training and testing sets, reserving about 80% for training and 20% for testing.\n\nX_train = X[:100000]\nX_test = X[100000:]\ny_train = y[:100000]\ny_test = y[100000:]\n\nModels typically perform better when input values are within a certain range, like [-1, 1] for example. We scale the data points appropriately.\n\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\nX_train\n\narray([[ 0.29976876, -1.55213354,  0.51397118],\n       [-0.19081527, -1.80102981,  0.51397118],\n       [ 0.45349097, -0.55854175,  0.51397118],\n       ...,\n       [-0.98926974, -0.04632361,  0.51397118],\n       [ 1.01246158,  2.31043674, -0.67408559],\n       [-0.93654137,  1.82255592,  0.51397118]])"
  },
  {
    "objectID": "2-rf-wind.html#training-the-models",
    "href": "2-rf-wind.html#training-the-models",
    "title": "Random Forest Regression Process and Analysis for Wind Data",
    "section": "Training the Models",
    "text": "Training the Models\nNow that the data is pre-processed accordingly, the models can be trained and fit.\n\nreg = RandomForestRegressor()\nreg.fit(X_train, y_train)\n\nRandomForestRegressor()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  RandomForestRegressor?Documentation for RandomForestRegressoriFittedRandomForestRegressor() \n\n\nWith a trained model, predictions can now be made.\n\ndisplay = y_test.reset_index()\npreds = reg.predict(X_test)\nprint(\"Predictions\")\nprint(\"----------------------\")\nfor i in range(3):\n    print(f\"predicted energy: {preds[i][0]:.2f}\\tactual energy: {display.at[i, 'generated_energy']:.2f}\\tpredicted cost: {preds[i][1]:.2f}\\tactual cost: {display.at[i, 'cost']:.2f}\")\n\nPredictions\n----------------------\npredicted energy: 83754.58  actual energy: 83847.86 predicted cost: 53602934.30 actual cost: 53662631.64\npredicted energy: 71218.08  actual energy: 72733.57 predicted cost: 45579569.00 actual cost: 46549485.59\npredicted energy: 12278.47  actual energy: 12532.50 predicted cost: 7367082.12  actual cost: 7519499.96"
  },
  {
    "objectID": "2-rf-wind.html#testing-and-analyzing-the-models",
    "href": "2-rf-wind.html#testing-and-analyzing-the-models",
    "title": "Random Forest Regression Process and Analysis for Wind Data",
    "section": "Testing and Analyzing the Models",
    "text": "Testing and Analyzing the Models\nThis section contains metrics gathering and other figures that visualize the models and its results.\n\nMetrics\n\nScores and Error Values\nThe score being recored are the R2 score, Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE).\n\nr2 = metrics.r2_score(y_test, preds, multioutput=\"raw_values\")\nrmse = metrics.root_mean_squared_error(y_test, preds, multioutput=\"raw_values\")\nmape = metrics.mean_absolute_percentage_error(y_test, preds, multioutput=\"raw_values\")\n\nprint(\"Metric\\tScore\")\nprint(\"-----------------------\")\nprint(f\"r2\\t{r2}\\nrmse\\t{rmse}\\nmape\\t{mape}\")\n\nMetric  Score\n-----------------------\nr2  [0.91837919 0.886822  ]\nrmse    [   9016.1235774  6597654.69852586]\nmape    [0.12685824 0.12691037]\n\n\n\n\nFeature Importances\nFeature importances give insights into the features that each decision tree in the random forest use to split most often. Results are portrayed in percentages.\n\nfeatures = ['lat','long','capacity',]\n\nimportances = reg.feature_importances_\nindices = np.argsort(importances)\n\nprint(\"Importances\")\nprint('----------------------')\nfor i in indices:\n    print(f\"{features[i]}: {importances[i]*100}\")\n\nImportances\n----------------------\ncapacity: 20.135246241505772\nlat: 35.00933261524246\nlong: 44.855421143251775\n\n\n\n\nK-Fold Cross Validation\nThis cross validation splits up the dataset into 10 unique folds, which are then used to test a model. The model is then scored using the same metrics outlined above: R2, RMSE, MAPE. This ensures the scoring is rigorous, and the entire dataset is used.\n\nkf = KFold(n_splits=10, random_state=0, shuffle=True)\nkf_cv_scores = cross_validate(reg, X, y, cv=kf, scoring={\"r2\":metrics.make_scorer(score_func=metrics.r2_score),\n \"rmse\":metrics.make_scorer(score_func=metrics.root_mean_squared_error),\n \"mape\":metrics.make_scorer(score_func=metrics.mean_absolute_percentage_error)})\nkf_cv_df = pd.DataFrame.from_dict(kf_cv_scores)\nmeans = kf_cv_df.mean()\nprint(\"10-Fold Cross Validation Scores\")\nprint(\"----------------------------------------------------\")\nprint(f\"R2 Average: {means.iloc[2]}\")\nprint(f\"RMSE Average: {means.iloc[3]}\")\nprint(f\"MAPE Average: {means.iloc[4]}\")\nkf_cv_df\n\n10-Fold Cross Validation Scores\n----------------------------------------------------\nR2 Average: 0.9109908237527048\nRMSE Average: 3181739.2057383326\nMAPE Average: 0.13390596472645255\n\n\n\n\n\n\n\n\n\nfit_time\nscore_time\ntest_r2\ntest_rmse\ntest_mape\n\n\n\n\n0\n35.631838\n0.412091\n0.908636\n3.244508e+06\n0.126463\n\n\n1\n35.085633\n0.407737\n0.909902\n3.194235e+06\n0.134273\n\n\n2\n34.784758\n0.409132\n0.912724\n3.128678e+06\n0.129694\n\n\n3\n34.819360\n0.401673\n0.908216\n3.253428e+06\n0.126229\n\n\n4\n34.879103\n0.404808\n0.907344\n3.241619e+06\n0.137367\n\n\n5\n34.481580\n0.417363\n0.915569\n3.113150e+06\n0.137573\n\n\n6\n35.357341\n0.434344\n0.908085\n3.232867e+06\n0.148030\n\n\n7\n37.669082\n0.456003\n0.915380\n3.138264e+06\n0.137533\n\n\n8\n37.000147\n0.439912\n0.913334\n3.138594e+06\n0.128061\n\n\n9\n34.930129\n0.409387\n0.910719\n3.132047e+06\n0.133837\n\n\n\n\n\n\n\n\n\n\nGraphs\nGraphs of the Random Forest model fits on each of the input features, for each target.\n\nplot_x = pd.DataFrame()\n\nplt.scatter(X.loc[:,[\"lat\"]], y.loc[:,['generated_energy']], color='darkorange', label='data')\nplt.plot(X_test, preds, color='c', label=\"model\")\nplt.xlabel(\"data\")\nplt.ylabel(\"target\")\nplt.title(\"Random Forest Regression\")\nplt.legend()\nplt.show()\n\nValueError: x has 3 columns but y has 2 columns\n\n\n\n\n\n\n\n\n\nA graph of the feature importances. This helps to visualize the magnitude of importance of each feature, and compare their impact against one another.\n\nplt.title(\"Feature Importances\")\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel(\"Relative Importance\")\nplt.show()\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\nA graph of one of the decision trees in the random forest. This displays the decision making process the model takes to arive at predictions.\n\nfn = ['lat','long','capacity']\ncn = ['generated_energy','cost']\nplt.subplots(nrows=1, ncols=1, figsize=(4,4), dpi=800)\ntree.plot_tree(reg.estimators_[0],feature_names=fn,class_names=cn,filled=True, max_depth=3)\nplt.show()\n\n\n\n\n\n\n\nFigure 2"
  },
  {
    "objectID": "2-rf-solar.html",
    "href": "2-rf-solar.html",
    "title": "Random Forest Regression Process and Analysis for Solar Data",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.legend_handler import HandlerLine2D\nimport sklearn.metrics as metrics\nfrom sklearn.model_selection import cross_validate, KFold\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import tree"
  },
  {
    "objectID": "2-rf-solar.html#imports",
    "href": "2-rf-solar.html#imports",
    "title": "Random Forest Regression Process and Analysis for Solar Data",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.legend_handler import HandlerLine2D\nimport sklearn.metrics as metrics\nfrom sklearn.model_selection import cross_validate, KFold\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import tree"
  },
  {
    "objectID": "2-rf-solar.html#data-preprocessing",
    "href": "2-rf-solar.html#data-preprocessing",
    "title": "Random Forest Regression Process and Analysis for Solar Data",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\nFirst, we read in the dataset.\n\ndf = pd.read_csv(\"../data/solar.csv\")\ndf.head(5)\n\n\n\n\n\n\n\n\nid\nlat\nlong\nstate\nfarm_type\nirradiance\nlcoe\ncapacity\ncapacity_factor\narray_area\navailable_solar_resource\ngenerated_energy\ncost\n\n\n\n\n0\n0\n25.896492\n-97.460358\nTexas\nlarge_community\n5.634079\n39\n5.00\n0.235\n90633.862770\n21.276596\n6132.00\n4782960.0\n\n\n1\n1\n26.032654\n-97.738098\nTexas\nsmall_utility\n5.616413\n39\n5.00\n0.234\n91307.484990\n21.367521\n6132.00\n4782960.0\n\n\n2\n2\n26.059063\n-97.208252\nTexas\nsmall_community\n5.746738\n39\n0.15\n0.239\n2621.097459\n0.627615\n183.96\n143488.8\n\n\n3\n3\n26.078449\n-98.073364\nTexas\nsmall_utility\n5.742196\n39\n5.00\n0.239\n87439.036330\n20.920502\n6132.00\n4782960.0\n\n\n4\n4\n26.143227\n-98.311340\nTexas\nsmall_utility\n5.817187\n39\n5.00\n0.242\n85241.850210\n20.661157\n6132.00\n4782960.0\n\n\n\n\n\n\n\nNow, we must shuffle the datasets to reduce bias.\n\ndf = df.sample(frac=1)\ndf.head(5)\n\n\n\n\n\n\n\n\nid\nlat\nlong\nstate\nfarm_type\nirradiance\nlcoe\ncapacity\ncapacity_factor\narray_area\navailable_solar_resource\ngenerated_energy\ncost\n\n\n\n\n4326\n4326\n34.633976\n-106.361832\nNew Mexico\nmedium_residential\n6.288012\n34\n0.010\n0.262\n1.456789e+02\n0.038168\n12.264\n8.339520e+03\n\n\n4006\n4006\n34.576786\n-102.597473\nTexas\nsmall_residential\n6.425785\n39\n0.005\n0.268\n6.968194e+01\n0.018657\n6.132\n4.782960e+03\n\n\n9751\n9751\n37.820488\n-105.240173\nColorado\nlarge_residential\n6.112310\n38\n0.015\n0.255\n2.309707e+02\n0.058824\n18.396\n1.398096e+04\n\n\n11363\n11363\n46.366371\n-123.463028\nWashington\nlarge_utility\n3.726862\n50\n2000.000\n0.155\n8.309334e+07\n12903.225810\n2452800.000\n2.452800e+09\n\n\n3362\n3362\n32.793304\n-114.747818\nCalifornia\nsmall_community\n6.840104\n41\n0.150\n0.285\n1.846694e+03\n0.526316\n183.960\n1.508472e+05\n\n\n\n\n\n\n\nLooking at each dataset, we can identify which variables we want to use for our models.\n\nX = df.loc[:, ['lat','long','capacity']]\ny = df.loc[:, ['generated_energy','cost']]\n\nNow we split into training and testing sets, reserving about 80% for training and 20% for testing.\n\nX_train = X[:9500]\nX_test = X[9500:]\ny_train = y[:9500]\ny_test = y[9500:]\n\nModels typically perform better when input values are within a certain range, like [-1, 1] for example. We scale the data points appropriately.\n\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\nX_train\n\narray([[-0.1222636 , -0.72300137, -0.43943183],\n       [-0.13674851, -0.24165866, -0.43943988],\n       [ 0.68480694, -0.57957659, -0.43942379],\n       ...,\n       [-0.13809139,  0.21964016, -0.43942379],\n       [-0.19139052, -0.60332559, -0.43140258],\n       [-0.26111264, -0.03741568, -0.43943988]])"
  },
  {
    "objectID": "2-rf-solar.html#training-the-models",
    "href": "2-rf-solar.html#training-the-models",
    "title": "Random Forest Regression Process and Analysis for Solar Data",
    "section": "Training the Models",
    "text": "Training the Models\nNow that the data is pre-processed accordingly, the models can be trained and fit.\n\nreg = RandomForestRegressor()\nreg.fit(X_train, y_train)\n\nRandomForestRegressor()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  RandomForestRegressor?Documentation for RandomForestRegressoriFittedRandomForestRegressor() \n\n\nWith a trained model, predictions can now be made.\n\ndisplay = y_test.reset_index()\npreds = reg.predict(X_test)\nprint(\"Predictions\")\nprint(\"----------------------\")\nfor i in range(3):\n    print(f\"predicted energy: {preds[i][0]:.2f}\\tactual energy: {display.at[i, 'generated_energy']:.2f}\\tpredicted cost: {preds[i][1]:.2f}\\tactual cost: {display.at[i, 'cost']:.2f}\")\n\nPredictions\n----------------------\npredicted energy: 6132.00   actual energy: 6132.00  predicted cost: 5028240.00  actual cost: 5028240.00\npredicted energy: 183.96    actual energy: 183.96   predicted cost: 125092.80   actual cost: 125092.80\npredicted energy: 12.26 actual energy: 12.26    predicted cost: 9565.92 actual cost: 9565.92"
  },
  {
    "objectID": "2-rf-solar.html#testing-and-analyzing-the-models",
    "href": "2-rf-solar.html#testing-and-analyzing-the-models",
    "title": "Random Forest Regression Process and Analysis for Solar Data",
    "section": "Testing and Analyzing the Models",
    "text": "Testing and Analyzing the Models\nThis section contains metrics gathering and other figures that visualize the models and its results.\n\nMetrics\n\nScores and Error Values\nThe score being recored are the R2 score, Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE).\n\nr2 = metrics.r2_score(y_test, preds, multioutput=\"raw_values\")\nrmse = metrics.root_mean_squared_error(y_test, preds, multioutput=\"raw_values\")\nmape = metrics.mean_absolute_percentage_error(y_test, preds, multioutput=\"raw_values\")\n\nprint(\"Metric\\tScore\")\nprint(\"-----------------------\")\nprint(f\"r2\\t{r2}\\nrmse\\t{rmse}\\nmape\\t{mape}\")\n\nMetric  Score\n-----------------------\nr2  [1.         0.99973199]\nrmse    [1.84203151e-12 1.00424139e+07]\nmape    [9.85642916e-16 4.44841521e-03]\n\n\n\n\nFeature Importances\nFeature importances give insights into the features that each decision tree in the random forest use to split most often. Results are portrayed in percentages.\n\nfeatures = ['lat','long','capacity',]\n\nimportances = reg.feature_importances_\nindices = np.argsort(importances)\n\nprint(\"Importances\")\nprint('----------------------')\nfor i in indices:\n    print(f\"{features[i]}: {importances[i]*100}\")\n\nImportances\n----------------------\nlong: 0.5023649924964896\nlat: 0.7420038684393504\ncapacity: 98.75563113906416\n\n\n\n\nK-Fold Cross Validation\nThis cross validation splits up the dataset into 10 unique folds, which are then used to test a model. The model is then scored using the same metrics outlined above: R2, RMSE, MAPE. This ensures the scoring is rigorous, and the entire dataset is used.\n\nkf = KFold(n_splits=10, random_state=0, shuffle=True)\nkf_cv_scores = cross_validate(reg, X, y, cv=kf, scoring={\"r2\":metrics.make_scorer(score_func=metrics.r2_score),\n \"rmse\":metrics.make_scorer(score_func=metrics.root_mean_squared_error),\n \"mape\":metrics.make_scorer(score_func=metrics.mean_absolute_percentage_error)})\nkf_cv_df = pd.DataFrame.from_dict(kf_cv_scores)\nmeans = kf_cv_df.mean()\nprint(\"10-Fold Cross Validation Scores\")\nprint(\"----------------------------------------------------\")\nprint(f\"R2 Average: {means.iloc[2]}\")\nprint(f\"RMSE Average: {means.iloc[3]}\")\nprint(f\"MAPE Average: {means.iloc[4]}\")\nkf_cv_df\n\n10-Fold Cross Validation Scores\n----------------------------------------------------\nR2 Average: 0.9997616578182351\nRMSE Average: 6164218.5242848415\nMAPE Average: 0.0019807060663228687\n\n\n\n\n\n\n\n\n\nfit_time\nscore_time\ntest_r2\ntest_rmse\ntest_mape\n\n\n\n\n0\n2.986361\n0.028260\n0.999850\n5.233825e+06\n0.002174\n\n\n1\n2.941958\n0.025449\n0.999925\n3.747869e+06\n0.001545\n\n\n2\n2.504921\n0.016603\n0.999602\n8.273457e+06\n0.002129\n\n\n3\n1.747063\n0.008211\n0.999855\n5.241678e+06\n0.001733\n\n\n4\n1.723520\n0.016229\n0.999739\n6.765095e+06\n0.001984\n\n\n5\n1.695485\n0.041037\n0.999856\n5.101608e+06\n0.001929\n\n\n6\n1.725523\n0.024756\n0.999421\n1.033441e+07\n0.002599\n\n\n7\n1.841746\n0.016647\n0.999955\n2.943068e+06\n0.002000\n\n\n8\n1.801206\n0.016318\n0.999573\n8.606798e+06\n0.002018\n\n\n9\n1.834907\n0.016288\n0.999840\n5.394372e+06\n0.001695\n\n\n\n\n\n\n\n\n\n\nGraphs\nA graph of the feature importances. This helps to visualize the magnitude of importance of each feature, and compare their impact against one another.\n\nplt.title(\"Feature Importances\")\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel(\"Relative Importance\")\nplt.show()\n\n\n\n\n\n\n\nFigure 1\n\n\n\n\n\nA graph of one of the decision trees in the random forest. This displays the decision making process the model takes to arive at predictions.\n\nfn = ['lat','long','capacity']\ncn = ['generated_energy','cost']\nplt.subplots(nrows=1, ncols=1, figsize=(4,4), dpi=800)\ntree.plot_tree(reg.estimators_[0],feature_names=fn,class_names=cn,filled=True, max_depth=3)\nplt.show()\n\n\n\n\n\n\n\nFigure 2"
  },
  {
    "objectID": "5-rf-old.html#graphsmetrics",
    "href": "5-rf-old.html#graphsmetrics",
    "title": "Old Random Forest Model",
    "section": "",
    "text": "features = ['lat','long','wind_speed','capacity','capacity_factor']\nimportances = reg.feature_importances_\nindices = np.argsort(importances)\n\nprint(\"Feature Importances\")\nprint('----------------------------')\nfor i in indices:\n    print(f\"{features[i]}: {importances[i]*100}\")\n\nFeature Importances\n----------------------------\nlat: 1.7415146179729832e-09\nlong: 4.556724073707158e-09\nwind_speed: 2.5874951940190983e-08\ncapacity_factor: 0.0005676720796435423\ncapacity: 99.99943229574717\n\n\n\nplt.title(\"Feature Importances\")\nplt.barh(range(len(indices)), importances[indices], color='b', align='center')\nplt.yticks(range(len(indices)), [features[i] for i in indices])\nplt.xlabel(\"Relative Importance\")\nplt.show()\n\n\n\n\n\n\n\nFigure 1"
  },
  {
    "objectID": "rf.html#a-note-about-the-solar-data",
    "href": "rf.html#a-note-about-the-solar-data",
    "title": "Random Forest Regression on Geospatial Data",
    "section": "",
    "text": "The solar data is not, and will, not be covered in detail like the wind data was above. It was concluded that the solar data is insufficient for the project’s goals. The metrics that come from a model trained on solar data indicate more than just poor results. It is omitted to reduce confusion and bring to light the more impactful results of this experiment.\n\n\n\nMetric  Score\n-----------------------\nr2  [1.         0.99973199]\nrmse    [1.84203151e-12 1.00424139e+07]\nmape    [9.85642916e-16 4.44841521e-03]\n\n\nSource: Random Forest Regression Process and Analysis for Solar Data\nNumbers that look like this are intrinsic of bad models or bad data. In this case, it is bad data. The issue stems from what data was available publically and feasible to work with. Many gaps needed to be filled in, and not enough data was available to fill these gaps in, in a way that did not comprimise the dataset in the end. The notebook is still available to view for purposes of experiment replication and validation."
  },
  {
    "objectID": "3-svm-wind.html",
    "href": "3-svm-wind.html",
    "title": "Support Vector Regression Process and Analysis for Wind Data",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.legend_handler import HandlerLine2D\nimport sklearn.metrics as metrics\nfrom sklearn.model_selection import cross_validate, KFold\nfrom sklearn import svm\nfrom sklearn.preprocessing import StandardScaler"
  },
  {
    "objectID": "3-svm-wind.html#imports",
    "href": "3-svm-wind.html#imports",
    "title": "Support Vector Regression Process and Analysis for Wind Data",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.legend_handler import HandlerLine2D\nimport sklearn.metrics as metrics\nfrom sklearn.model_selection import cross_validate, KFold\nfrom sklearn import svm\nfrom sklearn.preprocessing import StandardScaler"
  },
  {
    "objectID": "3-svm-wind.html#data-preprocessing",
    "href": "3-svm-wind.html#data-preprocessing",
    "title": "Support Vector Regression Process and Analysis for Wind Data",
    "section": "Data Preprocessing",
    "text": "Data Preprocessing\nFirst, we read in the dataset.\n\ndf = pd.read_csv(\"../data/wind.csv\")\ndf.head(5)\n\n\n\n\n\n\n\n\nid\nlat\nlong\nstate\nfarm_type\nwind_speed\nlcoe\ncapacity\ncapacity_factor\navailable_wind_power\navailable_energy\ngenerated_energy\ncost\n\n\n\n\n0\n0\n25.896492\n-97.460358\nTexas\nonshore\n7.46\n31\n2\n0.433\n1.997163\n17495.14630\n7575.398348\n4.696747e+06\n\n\n1\n1\n26.032654\n-97.738098\nTexas\nonshore\n7.45\n31\n10\n0.414\n9.945710\n87124.42376\n36069.511440\n2.236310e+07\n\n\n2\n2\n26.059063\n-97.208252\nTexas\nonshore\n8.18\n31\n2\n0.506\n2.633037\n23065.40088\n11671.092850\n7.236078e+06\n\n\n3\n3\n26.078449\n-98.073364\nTexas\nonshore\n7.17\n31\n16\n0.363\n14.185493\n124264.92160\n45108.166540\n2.796706e+07\n\n\n4\n4\n26.143227\n-98.311340\nTexas\nonshore\n7.06\n31\n16\n0.358\n13.542570\n118632.91080\n42470.582050\n2.633176e+07\n\n\n\n\n\n\n\nNow, we must shuffle the datasets to reduce bias.\n\ndf = df.sample(frac=1)\ndf.head(5)\n\n\n\n\n\n\n\n\nid\nlat\nlong\nstate\nfarm_type\nwind_speed\nlcoe\ncapacity\ncapacity_factor\navailable_wind_power\navailable_energy\ngenerated_energy\ncost\n\n\n\n\n73583\n73583\n42.929008\n-106.359589\nWyoming\nonshore\n8.50\n30\n16\n0.446\n23.634355\n207036.94960\n92338.47951\n55403087.71\n\n\n100710\n100710\n44.748081\n-117.324646\nOregon\nonshore\n5.62\n41\n16\n0.286\n6.831183\n59841.16362\n17114.57279\n14033949.69\n\n\n8945\n8945\n34.616692\n-101.352570\nTexas\nonshore\n7.13\n31\n16\n0.353\n13.949401\n122196.75490\n43135.45447\n26743981.77\n\n\n85386\n85386\n44.325836\n-99.711121\nSouth Dakota\nonshore\n8.15\n30\n16\n0.460\n20.833383\n182500.43730\n83950.20114\n50370120.69\n\n\n23406\n23406\n36.811668\n-103.798920\nNew Mexico\nonshore\n8.82\n33\n16\n0.391\n26.405399\n231311.29420\n90442.71603\n59692192.58\n\n\n\n\n\n\n\nLooking at each dataset, we can identify which variables we want to use for our models.\n\nX = df.loc[:, ['lat','long','capacity']]\ny_energy = df.loc[:, ['generated_energy']]\ny_cost = df.loc[:, ['cost']]\n\nNow we split into training and testing sets, reserving about 80% for training and 20% for testing.\n\nX_train = X[:100000]\nX_test = X[100000:]\ny_energy_train = y_energy[:100000]\ny_energy_test = y_energy[100000:]\ny_cost_train = y_cost[:100000]\ny_cost_test = y_cost[100000:]\n\nModels typically perform better when input values are within a certain range, like [-1, 1] for example. We scale the data points appropriately.\n\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)\n\nX_train\n\narray([[ 0.55054549, -0.63978892,  0.51384259],\n       [ 0.96789356, -1.56319528,  0.51384259],\n       [-1.35654073, -0.21813008,  0.51384259],\n       ...,\n       [ 0.56570845, -1.39986445,  0.51384259],\n       [-1.23758065, -0.43956329,  0.51384259],\n       [-0.05781529,  0.20089455,  0.51384259]])"
  },
  {
    "objectID": "3-svm-wind.html#training-the-models",
    "href": "3-svm-wind.html#training-the-models",
    "title": "Support Vector Regression Process and Analysis for Wind Data",
    "section": "Training the Models",
    "text": "Training the Models\nNow that the data is pre-processed accordingly, the models can be trained and fit.\n\nenergy_reg = svm.SVR()\ncost_reg = svm.SVR()\nenergy_reg.fit(X_train, y_energy_train)\ncost_reg.fit(X_train, y_cost_train)\n\nRandomForestRegressor()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  RandomForestRegressor?Documentation for RandomForestRegressoriFittedRandomForestRegressor() \n\n\nWith a trained model, predictions can now be made.\n\nenergy_display = y_energy_test.reset_index()\ncost_display = y_cost_test.reset_index()\nenergy_preds = energy_reg.predict(X_test)\ncost_preds = cost_reg.predict(X_test)\nprint(\"Predictions\")\nprint(\"----------------------\")\nfor i in range(3):\n    print(f\"predicted energy: {energy_preds[i]:.2f}\\tactual energy: {energy_display.at[i, 'generated_energy']:.2f}\\tpredicted cost: {cost_preds[i]:.2f}\\tactual cost: {cost_display.at[i, 'cost']:.2f}\")\n\nPredictions\n----------------------\npredicted energy: 65941.49  actual energy: 49377.51 predicted cost: 43521384.19 actual cost: 32589159.19\npredicted energy: 83998.00  actual energy: 89311.55 predicted cost: 52078761.10 actual cost: 55373161.14\npredicted energy: 69280.12  actual energy: 77909.82 predicted cost: 41568069.82 actual cost: 46745892.11"
  },
  {
    "objectID": "3-svm-wind.html#testing-and-analyzing-the-models",
    "href": "3-svm-wind.html#testing-and-analyzing-the-models",
    "title": "Support Vector Regression Process and Analysis for Wind Data",
    "section": "Testing and Analyzing the Models",
    "text": "Testing and Analyzing the Models\nThis section contains metrics gathering and other figures that visualize the models and its results.\n\nMetrics\n\nScores and Error Values\nThe score being recored are the R2 score, Root Mean Squared Error (RMSE), and Mean Absolute Percentage Error (MAPE).\n\nenergy_r2 = metrics.r2_score(y_energy_test, energy_preds, multioutput=\"raw_values\")\nenergy_rmse = metrics.root_mean_squared_error(y_energy_test, energy_preds, multioutput=\"raw_values\")\nenergy_mape = metrics.mean_absolute_percentage_error(y_energy_test, energy_preds, multioutput=\"raw_values\")\n\ncost_r2 = metrics.r2_score(y_cost_test, cost_preds, multioutput=\"raw_values\")\ncost_rmse = metrics.root_mean_squared_error(y_cost_test, cost_preds, multioutput=\"raw_values\")\ncost_mape = metrics.mean_absolute_percentage_error(y_cost_test, cost_preds, multioutput=\"raw_values\")\n\nprint(\"Metric\\tScore\")\nprint(\"-----------------------\")\nprint(f\"energy_r2\\t{energy_r2}\\ncost_r2\\t{cost_r2}\\nenergy_rmse\\t{energy_rmse}\\ncost_rmse\\t{cost_rmse}\\nenergy_mape\\t{energy_mape}\\ncost_mape\\t{cost_mape}\")\n\nMetric  Score\n-----------------------\nr2  [0.92812989 0.90036725]\nrmse    [   8577.69878655 6266978.52471402]\nmape    [0.13179711 0.13129718]\n\n\n\n\nK-Fold Cross Validation\nThis cross validation splits up the dataset into 10 unique folds, which are then used to test a model. The model is then scored using the same metrics outlined above: R2, RMSE, MAPE. This ensures the scoring is rigorous, and the entire dataset is used.\n\nkf = KFold(n_splits=10, random_state=0, shuffle=True)\nkf_cv_scores = cross_validate(reg, X, y, cv=kf, scoring={\"r2\":metrics.make_scorer(score_func=metrics.r2_score),\n \"rmse\":metrics.make_scorer(score_func=metrics.root_mean_squared_error),\n \"mape\":metrics.make_scorer(score_func=metrics.mean_absolute_percentage_error)})\nkf_cv_df = pd.DataFrame.from_dict(kf_cv_scores)\nmeans = kf_cv_df.mean()\nprint(\"10-Fold Cross Validation Scores\")\nprint(\"----------------------------------------------------\")\nprint(f\"R2 Average: {means.iloc[2]}\")\nprint(f\"RMSE Average: {means.iloc[3]}\")\nprint(f\"MAPE Average: {means.iloc[4]}\")\nkf_cv_df\n\n10-Fold Cross Validation Scores\n----------------------------------------------------\nR2 Average: 0.9109908237527048\nRMSE Average: 3181739.2057383326\nMAPE Average: 0.13390596472645255\n\n\n\n\n\n\n\n\n\nfit_time\nscore_time\ntest_r2\ntest_rmse\ntest_mape\n\n\n\n\n0\n35.631838\n0.412091\n0.908636\n3.244508e+06\n0.126463\n\n\n1\n35.085633\n0.407737\n0.909902\n3.194235e+06\n0.134273\n\n\n2\n34.784758\n0.409132\n0.912724\n3.128678e+06\n0.129694\n\n\n3\n34.819360\n0.401673\n0.908216\n3.253428e+06\n0.126229\n\n\n4\n34.879103\n0.404808\n0.907344\n3.241619e+06\n0.137367\n\n\n5\n34.481580\n0.417363\n0.915569\n3.113150e+06\n0.137573\n\n\n6\n35.357341\n0.434344\n0.908085\n3.232867e+06\n0.148030\n\n\n7\n37.669082\n0.456003\n0.915380\n3.138264e+06\n0.137533\n\n\n8\n37.000147\n0.439912\n0.913334\n3.138594e+06\n0.128061\n\n\n9\n34.930129\n0.409387\n0.910719\n3.132047e+06\n0.133837\n\n\n\n\n\n\n\n\n\n\nGraphs\nGraphs of the SVR model fits on each on the input features, for each target.\n\n\n\nplt.scatter(X.loc[:,['lat']], y_energy, color='darkorange', label='data')\nplt.scatter(X.loc[:,['long']], y_energy, color='darkorange', label='data')\nplt.scatter(X.loc[:,['capacity']], y_energy, color='darkorange', label='data')\n\n\nFigure 1"
  }
]